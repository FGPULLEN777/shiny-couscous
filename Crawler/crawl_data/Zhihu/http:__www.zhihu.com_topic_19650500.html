<!DOCTYPE html><html lang="zh-CN" dropEffect="none" class="no-js no-auth topic-pages"><head><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="renderer" content="webkit" /><title>线性回归 - 话题精华 - 知乎</title><meta name="apple-itunes-app" content="app-id=432274380" /><meta name="description" content="平均来讲，我们对一张面孔的相貌评价会随着看到这张脸的次数增加而发生什么样的变化？1126个最新问答，点击查看更多>>" /><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/><meta http-equiv="mobile-agent" content="format=html5;url=http://www.zhihu.com/topic/19650500/top-answers"><meta id="znonce" name="znonce" content="baff6fbaeaad46cd8ff0c01b0ed6924c"><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(57px).png" /><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(72px).png" sizes="72x72" /><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(76px).png" sizes="76x76" /><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(114px).png" sizes="114x114" /><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(120px).png" sizes="120x120" /><link rel="apple-touch-icon-precomposed" href="http://static.zhihu.com/static/img/ios/zhihu(152px).png" sizes="152x152" /><link rel="shortcut icon" href="http://static.zhihu.com/static/favicon.ico" type="image/x-icon"><link rel="search" type="application/opensearchdescription+xml" href="http://static.zhihu.com/static/search.xml" title="知乎" /><link rel="stylesheet" href="http://static.zhihu.com/static/revved/-/css/z.e721bf59.css"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg" /><meta property="qc:admins" content="14414345146201056375" /><!--[if lt IE 9]><script src="http://static.zhihu.com/static/components/respond/dest/respond.min.js"></script><link href="http://static.zhihu.com/static/components/respond/cross-domain/respond-proxy.html" id="respond-proxy" rel="respond-proxy" /><link href="/static/components/respond/cross-domain/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" /><script src="/static/components/respond/cross-domain/respond.proxy.js"></script><![endif]--><script src="http://static.zhihu.com/static/revved/-/js/instant.4b42dd60.js"></script><link rel="canonical" href="http://www.zhihu.com/topic/19650500" /></head><body class="zhi "><div role="navigation" class="zu-top"><div class="zg-wrap modal-shifting clearfix" id="zh-top-inner"><a href="/" class="zu-top-link-logo" id="zh-top-link-logo" data-za-c="view_home" data-za-a="visit_home" data-za-l="top_navigation_zhihu_logo">知乎</a><ul class="topnav-noauth clearfix"><li><a href="javascript:;" class="js-signup-noauth"><i class="zg-icon zg-icon-dd-home"></i>注册知乎</a></li><li><a href="javascript:;" class="js-signin-noauth">登录</a></li></ul><button class="zu-top-add-question" id="zu-top-add-question">提问</button><div role="search" id="zh-top-search" class="zu-top-search"><form method="GET" action="/search" id="zh-top-search-form" class="zu-top-search-form"><input type="hidden" name="type" value="question"><label for="q" class="hide-text">知乎搜索</label><input type="text" class="zu-top-search-input" id="q" name="q" autocomplete="off" value="" placeholder="搜索问题、话题或人"><button type="submit" class="zu-top-search-button"><span class="hide-text">搜索</span><span class="sprite-global-icon-magnifier-dark"></span></button></form></div><div id="zg-top-nav" class="zu-top-nav"><ul class="zu-top-nav-ul zg-clear"><li class="zu-top-nav-li " id="zh-top-nav-home"><a class="zu-top-nav-link" href="/" id="zh-top-link-home" data-za-c="view_home" data-za-a="visit_home" data-za-l="top_navigation_home">首页</a></li><li class="top-nav-topic-selector zu-top-nav-li current" id="zh-top-nav-topic"><a class="zu-top-nav-link" href="/topic" id="top-nav-dd-topic">话题</a></li><li class="zu-top-nav-li " id="zh-top-nav-explore"><a class="zu-top-nav-link" href="/explore">发现</a></li></ul><div class="zu-top-nav-live zu-noti7-popup zg-r5px no-hovercard" id="zh-top-nav-live-new" role="popup" tabindex="0"><div class="zu-top-nav-live-inner zg-r5px"><div class="zu-top-live-icon">&nbsp;</div><div class="zu-home-noti-inner" id="zh-top-nav-live-new-inner"><div class="zm-noti7-popup-tab-container clearfix" tabindex="0"><button class="zm-noti7-popup-tab-item message"><span class="icon">消息</span></button><button class="zm-noti7-popup-tab-item user"><span class="icon">用户</span></button><button class="zm-noti7-popup-tab-item thanks"><span class="icon">赞同和感谢</span></button></div></div><div class="zm-noti7-frame-border top"></div><div class="zm-noti7-frame"><div class="zm-noti7-content"><div class="zm-noti7-content-inner"><div class="zm-noti7-content-body"><div class="zm-noti7-popup-loading"><span class="noti-spinner-loading"></span></div></div></div></div><div class="zm-noti7-content" style="display:none;"><div class="zm-noti7-content-inner"><div class="zm-noti7-content-body"><div class="zm-noti7-popup-loading"><span class="noti-spinner-loading"></span></div></div></div></div><div class="zm-noti7-content" style="display:none;"><div class="zm-noti7-content-inner"><div class="zm-noti7-content-body"><div class="zm-noti7-popup-loading"><span class="noti-spinner-loading"></span></div></div></div></div></div><div class="zm-noti7-frame-border bottom"></div><div class="zm-noti7-popup-footer"><a href="/notifications" class="zm-noti7-popup-footer-all zg-right">查看全部 &raquo;</a><a href="/settings/notification" class="zm-noti7-popup-footer-set" title="通知设置" ><i class="zg-icon zg-icon-settings"></i></a></div></div></div></div></div></div><div class="zu-global-notify" id="zh-global-message" style="display:none"><div class="zg-wrap"><div class="zu-global-nitify-inner"><a class="zu-global-notify-close" href="javascript:;" title="关闭" name="close">x</a><span class="zu-global-notify-icon"></span><span class="zu-global-notify-msg"></span></div></div></div><div class="zg-wrap zu-main clearfix "  role="main"><div class="zu-main-content"><div class="zu-main-content-inner"><div itemscope itemtype="https://schema.org/CreativeWork/Topic"><div class="topic-avatar" itemprop="image" itemscope itemtype="http://schema.org/ImageObject"><div><a class="zm-entry-head-avatar-link" href="/topic/19650500" id="zh-avartar-edit-form"><img alt="线性回归" src="https://pic4.zhimg.com/1786ec53f_m.jpg" class="zm-avatar-editor-preview"></a><meta itemprop="image" content="https://pic4.zhimg.com/1786ec53f_l.jpg" /></div></div><div class="topic-info"><div class="topic-name" id="zh-topic-title"><h1 class="zm-editable-content" data-disabled="1">线性回归</h1><div class="zm-editable-editor-wrap" style="display:none"><input type="text" class="zm-editable-editor-input zg-form-text-input" style="width:150px" /><span class="zm-command"><a href="javascript:;" name="save" class="zg-btn-blue" style="margin:0 15px;">完成</a><a href="javascript:;" name="cancel" class="zm-command-cancel">取消</a></span></div></div><div class="zm-topic-topbar"><div class="zm-topic-topbar-nav"><ul class="zm-topic-topbar-nav-list clearfix"><li class="zm-topic-topbar-nav-list-item"><a class="zg-link-litblue-normal" href="/topic/19650500/hot">动态</a></li><li class="zm-topic-topbar-nav-list-item current"><span>精华</span></li><li class="zm-topic-topbar-nav-list-item"><a class="zg-link-litblue-normal" href="/topic/19650500/questions">全部问题</a></li></ul></div></div></div><div class="zm-topic-list-container" itemprop="hasPart" itemscope itemtype="http://schema.org/ItemList/QuestionList"><div class="zu-top-feed-list" id="zh-topic-top-page-list"><meta itemprop="questionCount" content="121" /><meta itemprop="topAnswerCount" content="22" /><div class="feed-item feed-item-hook folding combine first-combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='1'><meta itemprop="answer-id" content="21959147" /><meta itemprop="answerCount" content="551" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/27007650">平均来讲，我们对一张面孔的相貌评价会随着看到这张脸的次数增加而发生什么样的变化？</a></h2><div class="entry-body "data-aid="21959147"data-atoken="66354495"data-collapsed="False"data-created="1444013845"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="4610">4610</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">4610</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$527hao-xiao-guai-shou" href="/people/527hao-xiao-guai-shou">527号小怪兽</a>，<span title="微信公众号：sylvia_527。" class="bio">微信公众号：sylvia_527。</span></div><div class="zm-item-vote-info " data-votecount="4610"><span class="voters"><span class="user-block"><a data-tip="p$t$wang-shan-hong-81" href="http://www.zhihu.com/people/wang-shan-hong-81" class="zg-link" title="holly">holly</a>、</span><span class="user-block"><a data-tip="p$t$zi-fei-yu-mo-90" href="http://www.zhihu.com/people/zi-fei-yu-mo-90" class="zg-link" title="子非鱼Mo">子非鱼Mo</a>、</span><span class="user-block"><a data-tip="p$t$candyai-chi-tang" href="http://www.zhihu.com/people/candyai-chi-tang" class="zg-link" title="Candy爱吃糖">Candy爱吃糖</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="2986052" data-action="/answer/content" data-author-name="527号小怪兽" data-entry-url="/question/27007650/answer/66354495"><textarea class="content hidden">如果不考虑性格，只说相貌本身的话。&lt;br&gt;&lt;b&gt;&lt;br&gt;&lt;br&gt;情况一：看一张脸次数越多，觉得越好看。&lt;/b&gt;&lt;br&gt;&lt;br&gt;这个现象叫做Mere exposure effect（单纯曝光效应），社会心理学上有过很完整的研究。&lt;br&gt;&lt;br&gt;Mere exposure effect指的是：&lt;b&gt;一件事物，如果反复在你面前出现，即使并不去主观地去注意它，你的潜意识里却也会增加对它的好感。&lt;/b&gt;Goetzinger (1968) 的实验中，他让一个学生每天套着一个黑色的大袋子去上课（除了脚以外什么都看不见），然后观察班上其他学生的反应。果然，其他学生对黑色大袋子的态度随着时间的推移，逐渐从敌意转为好奇最终变为友善。&lt;br&gt;&lt;br&gt;在类似的许多实验中，心理学家们也发现，不管是人脸、画作、声音、汉字（对于不会中文的人而言），只要见得越多，就越容易产生好感。&lt;br&gt;&lt;br&gt;为什么会产生这种现象呢？首先要解释一个概念——&lt;b&gt;Perceptual fluency/Processing fluency（感知流畅性）&lt;/b&gt;。我们在感知一件事物的时候，会根据它的复杂程度，整合记忆中已有的信息来对它做出判断。因此，一件事物出现的频率越高，我们对它进行感知的次数越多，这个过程就越流畅、越容易。这种感知时的流畅性让我们觉得轻松不累，从而潜意识里转换为对所感知事物的好感。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;情况二：看一张脸次数越多，觉得其实也不过尔尔。&lt;/b&gt;&lt;br&gt;&lt;br&gt;关于这个现象，心理学界并没有统一的公论和解释，那么在这里，我想做一些自己的推断和揣测。&lt;br&gt;&lt;br&gt;社会学家Elaine Hatfield提出过一个Matching hypothesis（匹配假说），大意是说人们倾向于寻找相貌上与自己相匹配的人作为长期关系的伴侣。心理学实验中也用数据验证了这个观点：当一对伴侣颜值相当时，他们往往会更多地表现出对彼此的爱意。&lt;br&gt;&lt;br&gt;那么在这种情况下，一个颜值一般的人，频频见到颜值高的对象时，要用什么方式说服自己「其实我和TA也有发展的可能」呢？对，就是下调自己对其相貌的评价。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;结论：&lt;/b&gt;&lt;b&gt;心理学界较为公认的理论是越熟悉的事物越容易产生好感，因此，如果只是平均来讲，看到同一张脸的次数越多，我们对其相貌的评价就会越高。&lt;/b&gt;&lt;br&gt;&lt;br&gt;至于看一张脸次数越多，相貌评价越低这件事，我提出了自己的一种假说，欢迎共同补充探讨：）<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2015-10-05" target="_blank" href="/question/27007650/answer/66354495">编辑于 2015-10-05</a></span></textarea><div class="zh-summary summary clearfix">如果不考虑性格，只说相貌本身的话。<b>情况一：看一张脸次数越多，觉得越好看。</b>这个现象叫做Mere exposure effect（单纯曝光效应），社会心理学上有过很完整的研究。Mere exposure effect指的是：<b>一件事物，如果反复在你面前出现，即使并不去主观地去注意它，…</b><a href="/question/27007650/answer/66354495" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-2986052"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>630 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='2'><meta itemprop="answer-id" content="21970672" /><meta itemprop="answerCount" content="551" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/27007650">平均来讲，我们对一张面孔的相貌评价会随着看到这张脸的次数增加而发生什么样的变化？</a></h2><div class="entry-body "data-aid="21970672"data-atoken="66383349"data-collapsed="False"data-created="1444029788"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="662">662</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">662</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$chen-xi-kai-3" href="/people/chen-xi-kai-3">感谢我不可以</a>，<span title="杂学末流，奇技淫巧" class="bio">杂学末流，奇技淫巧</span></div><div class="zm-item-vote-info " data-votecount="662"><span class="voters"><span class="user-block"><a data-tip="p$t$waitxxx" href="http://www.zhihu.com/people/waitxxx" class="zg-link" title="WAITXXX">WAITXXX</a>、</span><span class="user-block"><a data-tip="p$t$1223-99-28" href="http://www.zhihu.com/people/1223-99-28" class="zg-link" title="依米">依米</a>、</span><span class="user-block"><a data-tip="p$t$da-fen-qi-7-22" href="http://www.zhihu.com/people/da-fen-qi-7-22" class="zg-link" title="达芬奇">达芬奇</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="2986052" data-action="/answer/content" data-author-name="感谢我不可以" data-entry-url="/question/27007650/answer/66383349"><textarea class="content hidden">不会啊，我看了自己二十多年也没觉得自己有多帅<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/27007650/answer/66383349">发布于 2015-10-05</a></span></textarea><div class="zh-summary summary clearfix">不会啊，我看了自己二十多年也没觉得自己有多帅</div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-2986052"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>121 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='3'><meta itemprop="answer-id" content="25208640" /><meta itemprop="answerCount" content="60" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/36845076">线性代数有什么用？学习线性代数的意义在哪？</a></h2><div class="entry-body "data-aid="25208640"data-atoken="74463428"data-collapsed="False"data-created="1448783471"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="537">537</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">537</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="537"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$kimi-wu" href="http://www.zhihu.com/people/kimi-wu" class="zg-link" title="kimi Wu">kimi Wu</a>、</span><span class="user-block"><a data-tip="p$t$liu-rong-34-97" href="http://www.zhihu.com/people/liu-rong-34-97" class="zg-link" title="天象">天象</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="6945257" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/36845076/answer/74463428"><textarea class="content hidden">谢邀。学线性代数有什么用？用处可大了！可以说线性代数不管是实用性上来说，还是从对未来更有用的课程的理解上来说，都是作用大大的。&lt;br&gt;&lt;br&gt;这里不得不提一句，国内的线性代数教材非常的差。翻一翻国内的教材，基本上着重点在运算上，然而在计算机如此发达的今天，绝大多数情况下怎么去计算矩阵的乘积、矩阵的秩实际上并没有太大意义，重要的是计算的原理。而线性代数中最为重要的理念，比如线性空间、线性变换对于理解代数甚至高层次的数学都是非常有帮助的。如果想仔细深入理解线性代数，推荐看国外的教材。&lt;br&gt;&lt;br&gt;简单举几个例子吧。&lt;br&gt;&lt;br&gt;1、现在有两个n维向量&lt;img src=&quot;//zhihu.com/equation?tex=%28x_1%2Cx_2%2C...x_n%29&quot; alt=&quot;(x_1,x_2,...x_n)&quot; eeimg=&quot;1&quot;&gt;、&lt;img src=&quot;//zhihu.com/equation?tex=%28y_1%2Cy_2%2C...y_n%29&quot; alt=&quot;(y_1,y_2,...y_n)&quot; eeimg=&quot;1&quot;&gt;，我们可以定义内积：&lt;img src=&quot;//zhihu.com/equation?tex=%3Cx%2Cy%3E%3Dx_1%5Ccdot+y_1%2B%5Ccdot+y_2%2B...%2Bx_n%5Ccdot+y_n&quot; alt=&quot;&amp;lt;x,y&amp;gt;=x_1\cdot y_1+\cdot y_2+...+x_n\cdot y_n&quot; eeimg=&quot;1&quot;&gt;。有了内积的定义，我们可以另外定义两个概念：距离和正交。距离可以定义为：&lt;img src=&quot;//zhihu.com/equation?tex=%7C%7Cx%7C%7C%3D%5Csqrt%7B%3Cx%2Cx%3E%7D+&quot; alt=&quot;||x||=\sqrt{&amp;lt;x,x&amp;gt;} &quot; eeimg=&quot;1&quot;&gt;，两个向量x和y正交如果：&lt;img src=&quot;//zhihu.com/equation?tex=%3Cx%2Cy%3E%3D0&quot; alt=&quot;&amp;lt;x,y&amp;gt;=0&quot; eeimg=&quot;1&quot;&gt;。&lt;br&gt;&lt;br&gt;现在假设有n个向量：&lt;img src=&quot;//zhihu.com/equation?tex=e_1%2Ce_2...e_n&quot; alt=&quot;e_1,e_2...e_n&quot; eeimg=&quot;1&quot;&gt;，且满足：&lt;img src=&quot;//zhihu.com/equation?tex=%3Ce_i%2Ce_j%3E%3D0&quot; alt=&quot;&amp;lt;e_i,e_j&amp;gt;=0&quot; eeimg=&quot;1&quot;&gt;，那么我们说这n个向量组成了一组正交基。下面讨论规范化的正交基，即&lt;img src=&quot;//zhihu.com/equation?tex=%7C%7Ce_i%7C%7C%3D1&quot; alt=&quot;||e_i||=1&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;&lt;br&gt;现在定义&lt;img src=&quot;//zhihu.com/equation?tex=a_i%3D%3Cx%2Ce_i%3E&quot; alt=&quot;a_i=&amp;lt;x,e_i&amp;gt;&quot; eeimg=&quot;1&quot;&gt;，那么可以得到&lt;img src=&quot;//zhihu.com/equation?tex=x%3D%5Csum_%7Bi%3D1%7D%5En+a_i%5Ccdot+e_i&quot; alt=&quot;x=\sum_{i=1}^n a_i\cdot e_i&quot; eeimg=&quot;1&quot;&gt;，或者写成：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=x%3DEa%2C+a%3D%28a_1%2Ca_2%2C...a_n%29%27%2C+E%3D%5Be_1%2Ce_2%2C...e_n%5D&quot; alt=&quot;x=Ea, a=(a_1,a_2,...a_n)', E=[e_1,e_2,...e_n]&quot; eeimg=&quot;1&quot;&gt;，同时有&lt;img src=&quot;//zhihu.com/equation?tex=E%27E%3DI&quot; alt=&quot;E'E=I&quot; eeimg=&quot;1&quot;&gt;。&lt;br&gt;&lt;br&gt;好了，那么a就是x在由&lt;img src=&quot;//zhihu.com/equation?tex=e_1%2Ce_2...e_n&quot; alt=&quot;e_1,e_2...e_n&quot; eeimg=&quot;1&quot;&gt;组成的坐标系中的坐标。最简单的比如&lt;img src=&quot;//zhihu.com/equation?tex=e_i%3D%280%2C0%2C...1%2C...0%29%27&quot; alt=&quot;e_i=(0,0,...1,...0)'&quot; eeimg=&quot;1&quot;&gt;，也就是我们经常使用的坐标系。&lt;br&gt;&lt;br&gt;说这么多有什么用呢？你可能还记得傅里叶级数。好了，我们现在把任何一个函数想象成一个向量，我们找一组函数，比如&lt;img src=&quot;//zhihu.com/equation?tex=sin%28nx%29%2C+cos%28mx%29&quot; alt=&quot;sin(nx), cos(mx)&quot; eeimg=&quot;1&quot;&gt;，我们可以知道，&lt;img src=&quot;//zhihu.com/equation?tex=%5Cint_0%5E%7B2%5Cpi%7D+sin%28nx%29cos%28mx%29dx%3D0&quot; alt=&quot;\int_0^{2\pi} sin(nx)cos(mx)dx=0&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Cint_0%5E%7B2%5Cpi%7D+cos%28nx%29cos%28mx%29dx%3D0%2Cn%5Cne+m&quot; alt=&quot;\int_0^{2\pi} cos(nx)cos(mx)dx=0,n\ne m&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Cint_0%5E%7B2%5Cpi%7D+sin%28nx%29sin%28mx%29dx%3D0%2Cn%5Cne+m&quot; alt=&quot;\int_0^{2\pi} sin(nx)sin(mx)dx=0,n\ne m&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;你想到了啥？对了。如果把积分看成是“内积”，那么以上的sin cos函数就变成了一组正交基，再仔细看一下傅里叶级数的公式，傅里叶级数无非就是把一个函数往这个正交基上进行投影。所以傅里叶级数其实就是得到了一组“坐标”而已。当然了，这个坐标是无穷维的。学好了线性代数，一般意义上的n维空间能够想象，扩展到无穷维的傅里叶变幻也就没啥了。而一旦你掌握了傅里叶级数，那么声音频谱处理、图像压缩等等一些初级技术，也就没啥问题了。&lt;br&gt;&lt;br&gt;2、现在考虑一个矩阵A，n-by-n维。一个x维的向量与其相乘意味着什么？&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=y%3DAx%3D%5Ba_1%2Ca_2...a_n%5D%28x_1%2Cx_2...x_n%29%27%3D%5Csum_%7Bi%3D1%7D%5En+a_i%5Ccdot+x_i&quot; alt=&quot;y=Ax=[a_1,a_2...a_n](x_1,x_2...x_n)'=\sum_{i=1}^n a_i\cdot x_i&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;也就是把A的列向量的一个线性组合。同时，A这个矩阵把一个n维空间的点x映射到了n维空间的另一个点y，我们把这种映射叫做变换。（关于线性变换，有一大堆可以写的，在此不说了，理解了线性变换才真正理解了矩阵）&lt;br&gt;&lt;br&gt;线性变换有很多实用的例子，比如最简单的，如果我有一个图像，需要旋转、放大该怎么做呢？用线性变换。比如：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=A%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7Dcos%5Ctheta+%26+-sin%5Ctheta%5C%5C+sin%5Ctheta+%26+cos%5Ctheta+%5Cend%7Barray%7D+%5Cright%5D+&quot; alt=&quot;A=\left[\begin{array}{cc}cos\theta &amp;amp; -sin\theta\\ sin\theta &amp;amp; cos\theta \end{array} \right] &quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;这个矩阵乘以任意一个向量x，就把这个点逆时针旋转了&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;度。以上也就是计算机处理二维、三维图像的原理。&lt;br&gt;&lt;br&gt;3、说起线性变换，有一类特殊的线性变换，叫做投影。比如我有k个n维空间的向量&lt;img src=&quot;//zhihu.com/equation?tex=%5Bx_1%2C...%2Cx_k%5D%3DX&quot; alt=&quot;[x_1,...,x_k]=X&quot; eeimg=&quot;1&quot;&gt;，我现在希望找到一个X的线性组合，使得新得到的点与空间上的其他点y距离最小。那么可以证明，这个点为：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Chat+y%3DX%28X%27X%29%5E%7B-1%7DX%27y&quot; alt=&quot;\hat y=X(X'X)^{-1}X'y&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;现在记矩阵&lt;img src=&quot;//zhihu.com/equation?tex=P%3DX%28X%27X%29%5E%7B-1%7DX%27%2C+M%3DI-P&quot; alt=&quot;P=X(X'X)^{-1}X', M=I-P&quot; eeimg=&quot;1&quot;&gt;，可以得到：&lt;img src=&quot;//zhihu.com/equation?tex=P%5E2%3DP%2C+M%5E2%3DM%2C+MP%3DPM%3D0&quot; alt=&quot;P^2=P, M^2=M, MP=PM=0&quot; eeimg=&quot;1&quot;&gt;。&lt;br&gt;上面的两个矩阵，P和M，因为其乘积等于其本身，所以成为幂等矩阵。幂等矩阵跟正交投影是一一对应的。&lt;br&gt;对于任何两个向量&lt;img src=&quot;//zhihu.com/equation?tex=x%2Cy&quot; alt=&quot;x,y&quot; eeimg=&quot;1&quot;&gt;，可以得到&lt;img src=&quot;//zhihu.com/equation?tex=%28Mx%29%27%28Py%29%3Dx%27MPy%3D0&quot; alt=&quot;(Mx)'(Py)=x'MPy=0&quot; eeimg=&quot;1&quot;&gt;，所以经过M和P的变换之后的向量正交。&lt;br&gt;如果你仔细观察，会发现以上推导的东西就是最小二乘法OLS。最小二乘法的很多优良性质都可以使用幂等矩阵推导出来，特别是小样本性质，基本上离不开幂等矩阵。比如最简单的，根据勾股定理：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=y%27y%3D%5Chat+y%27+%5Chat+y+%2Be%27e%3Dy%27Py%2By%27My&quot; alt=&quot;y'y=\hat y' \hat y +e'e=y'Py+y'My&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;&lt;br&gt;如果把正交投影这个概念推广到概率空间，那就是条件期望的概念了。什么迭代期望公式之类的，都可以用这个正交投影进行类比。&lt;br&gt;&lt;br&gt;4、说个实际点的应用吧。Morkov链相信大家都听说过。如果向量&lt;img src=&quot;//zhihu.com/equation?tex=x_t&quot; alt=&quot;x_t&quot; eeimg=&quot;1&quot;&gt;代表了t期的状态概率分布，根据马尔科夫性的假设，下一期的状态分布&lt;img src=&quot;//zhihu.com/equation?tex=x_%7Bt%2B1%7D&quot; alt=&quot;x_{t+1}&quot; eeimg=&quot;1&quot;&gt;只跟上一期有关，跟&lt;img src=&quot;//zhihu.com/equation?tex=x_%7Bt-1%7D%2Cx_%7Bt-2%7D%2C...&quot; alt=&quot;x_{t-1},x_{t-2},...&quot; eeimg=&quot;1&quot;&gt;都没有关系，那么可以把下一期的状态分布写成：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=x_%7Bt%2B1%7D%3DTx_t&quot; alt=&quot;x_{t+1}=Tx_t&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;其中T为马尔科夫矩阵，即第(i,j)个元素为从状态i到状态j的概率，且每行加起来等于1.&lt;br&gt;比如：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=T%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bccc%7D0.8+%26+0.1+%26+0.1%5C%5C+0.2+%26+0.6+%26+0.2%5C%5C+0.1+%26+0.1+%26+0.8+%5Cend%7Barray%7D+%5Cright%5D+&quot; alt=&quot;T=\left[\begin{array}{ccc}0.8 &amp;amp; 0.1 &amp;amp; 0.1\\ 0.2 &amp;amp; 0.6 &amp;amp; 0.2\\ 0.1 &amp;amp; 0.1 &amp;amp; 0.8 \end{array} \right] &quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;那么一个自然的问题是，当t趋向于无穷，稳定状态是什么呢？很简单，把T进行特征值分解，对于特征值为1的特征向量就是平稳的分布，比如在这个例子里，平稳的分布是（2/5, 1/5, 2/5）。&lt;br&gt;&lt;br&gt;另外一个有趣的例子是，如果T代表的不是状态，而是几个网页。比如&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=T%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bccc%7D0+%26+0.5+%26+0.5%5C%5C+1+%26+0+%26+0%5C%5C+0.5+%26+0.5+%26+0+%5Cend%7Barray%7D+%5Cright%5D+&quot; alt=&quot;T=\left[\begin{array}{ccc}0 &amp;amp; 0.5 &amp;amp; 0.5\\ 1 &amp;amp; 0 &amp;amp; 0\\ 0.5 &amp;amp; 0.5 &amp;amp; 0 \end{array} \right] &quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;这里的T意味着，第一个页面引用了第2\3个页面，第2个页面引用了第1个页面，第三个页面引用了第1、2个页面，那么这几个页面的重要程度如何呢？&lt;br&gt;&lt;br&gt;这里可以这么想，一个无聊上网的人，从随机的任何一页开始看，并完全随机的点击页面上的链接，那么当这个无聊透顶的人不断的点击之后，这些网页被点击的概率分布是怎样的？&lt;br&gt;&lt;br&gt;同样的思路，特征值分解，得到最终稳定的分布为（4/9,3/9,2/9），那么这些网页的重要性也就评出来了。&lt;br&gt;&lt;br&gt;这也就是Google的排序算法PageRank的一个简化版本<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2015-11-29" target="_blank" href="/question/36845076/answer/74463428">编辑于 2015-11-29</a></span></textarea><div class="zh-summary summary clearfix">谢邀。学线性代数有什么用？用处可大了！可以说线性代数不管是实用性上来说，还是从对未来更有用的课程的理解上来说，都是作用大大的。这里不得不提一句，国内的线性代数教材非常的差。翻一翻国内的教材，基本上着重点在运算上，然而在计算机如此发达的今天…<a href="/question/36845076/answer/74463428" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-6945257"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>59 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine first-combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='4'><meta itemprop="answer-id" content="17605961" /><meta itemprop="answerCount" content="54" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/32246256">用简单易懂的语言描述过拟合 overfitting？</a></h2><div class="entry-body "data-aid="17605961"data-atoken="55496955"data-collapsed="False"data-created="1437184601"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="303">303</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">303</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><span class="name">知乎用户</span>，<span title="data science" class="bio">data science</span></div><div class="zm-item-vote-info " data-votecount="303"><span class="voters"><span class="user-block"><a data-tip="p$t$chen-ming-12-84-1" href="http://www.zhihu.com/people/chen-ming-12-84-1" class="zg-link" title="陈明">陈明</a>、</span><span class="user-block"><a data-tip="p$t$xie-dai-yue" href="http://www.zhihu.com/people/xie-dai-yue" class="zg-link" title="薛岱月">薛岱月</a>、</span><span class="user-block"><a data-tip="p$t$lzllovesyl" href="http://www.zhihu.com/people/lzllovesyl" class="zg-link" title="小小林">小小林</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="5097916" data-action="/answer/content" data-author-name="不求东西" data-entry-url="/question/32246256/answer/55496955"><textarea class="content hidden">想起了以前看过的一个笑话&lt;br&gt;----------------&lt;br&gt;&lt;br&gt;一個非洲酋長到倫敦訪問，一群記者在機場截住了他。&lt;br&gt;&lt;br&gt;早上好，酋長先生&quot;， 其中一人問道：你的路途舒適嗎？&lt;br&gt;&lt;br&gt;酋長發出了一連串刺耳的聲音哄、哼、啊、吱、嘶嘶，&lt;br&gt;&lt;br&gt;然后用純正的英語說 道 ：是的，非常地舒適。&lt;br&gt;&lt;br&gt;那麼！您准備在這里待多久？&lt;br&gt;&lt;br&gt;他發出了同樣的一連串噪音，&lt;br&gt;&lt;br&gt;然後答：大約三星期，我想。&lt;br&gt;&lt;br&gt;酋長，告訴我，你是在哪學的這樣流利的英語？迷惑不解的記者問。&lt;br&gt;&lt;br&gt;又是一陣哄、吭、啊、吱、嘶嘶聲，&lt;br&gt;&lt;br&gt;酋長說：從短波收音機裡。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2015-07-18" target="_blank" href="/question/32246256/answer/55496955">编辑于 2015-07-18</a></span></textarea><div class="zh-summary summary clearfix">想起了以前看过的一个笑话----------------一個非洲酋長到倫敦訪問，一群記者在機場截住了他。早上好，酋長先生"， 其中一人問道：你的路途舒適嗎？酋長發出了一連串刺耳的聲音哄、哼、啊、吱、嘶嘶，然后用純正的英語說 道 ：是的，非常地舒適。那麼！您准…<a href="/question/32246256/answer/55496955" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-5097916"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>18 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='5'><meta itemprop="answer-id" content="17507663" /><meta itemprop="answerCount" content="54" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/32246256">用简单易懂的语言描述过拟合 overfitting？</a></h2><div class="entry-body "data-aid="17507663"data-atoken="55251597"data-collapsed="False"data-created="1437014525"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="182">182</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">182</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$yokuhn-67" href="/people/yokuhn-67">郑昆</a>，<span title="爱听爵士的本科疯" class="bio">爱听爵士的本科疯</span></div><div class="zm-item-vote-info " data-votecount="182"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$chen-ming-12-84-1" href="http://www.zhihu.com/people/chen-ming-12-84-1" class="zg-link" title="陈明">陈明</a>、</span><span class="user-block"><a data-tip="p$t$hqwsky" href="http://www.zhihu.com/people/hqwsky" class="zg-link" title="John">John</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="5097916" data-action="/answer/content" data-author-name="郑昆" data-entry-url="/question/32246256/answer/55251597"><textarea class="content hidden">其实不完全是噪声和假规律会造成过拟合。&lt;br&gt;(1)打个形象的比方，给一群天鹅让机器来学习天鹅的特征，经过训练后，知道了天鹅是有翅膀的，天鹅的嘴巴是长长的弯曲的，天鹅的脖子是长长的有点曲度，天鹅的整个体型像一个“2”且略大于鸭子.这时候你的机器已经基本能区别天鹅和其他动物了。&lt;br&gt;(2)然后，很不巧你的天鹅全是白色的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅.&lt;br&gt;(3)好，来分析一下上面这个例子：(1)中的规律都是对的，所有的天鹅都有的特征，是全局特征；然而，(2)中的规律：天鹅的羽毛是白的.这实际上并不是所有天鹅都有的特征，只是局部样本的特征。机器在学习全局特征的同时，又学习了局部特征，这才导致了不能识别黑天鹅的情况.&lt;br&gt;--------------------------------------------------理论总结分割线----------------------------------------&lt;br&gt;(1)对于机器来说，在使用学习算法学习数据的特征的时候，样本数据的特征可以分为局部特征和全局特征，全局特征就是任何你想学习的那个概念所对应的数据都具备的特征，而局部特征则是你用来训练机器的样本里头的数据专有的特征.&lt;br&gt;(2)在学习算法的作用下，机器在学习过程中是无法区别局部特征和全局特征的，于是机器在完成学习后，除了学习到了数据的全局特征，也可能习得一部分局部特征，而习得的局部特征比重越多，那么新样本中不具有这些局部特征但具有所有全局特征的样本也越多，于是机器无法正确识别符合概念定义的“正确”样本的几率也会上升，也就是所谓的“泛化性”变差，这是过拟合会造成的最大问题.&lt;br&gt;(3)所谓过拟合，就是指把学习进行的太彻底，把样本数据的所有特征几乎都习得了，于是机器学到了过多的局部特征，过多的由于噪声带来的假特征，造成模型的“泛化性”和识别正确率几乎达到谷点，于是你用你的机器识别新的样本的时候会发现就没几个是正确识别的.&lt;br&gt;(4)解决过拟合的方法，其基本原理就是限制机器的学习，使机器学习特征时学得不那么彻底，因此这样就可以降低机器学到局部特征和错误特征的几率，使得识别正确率得到优化.&lt;br&gt;(5)从上面的分析可以看出，要防止过拟合，训练数据的选取也是很关键的，良好的训练数据本身的局部特征应尽可能少，噪声也尽可能小.<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2015-07-16" target="_blank" href="/question/32246256/answer/55251597">编辑于 2015-07-16</a></span></textarea><div class="zh-summary summary clearfix">其实不完全是噪声和假规律会造成过拟合。(1)打个形象的比方，给一群天鹅让机器来学习天鹅的特征，经过训练后，知道了天鹅是有翅膀的，天鹅的嘴巴是长长的弯曲的，天鹅的脖子是长长的有点曲度，天鹅的整个体型像一个“2”且略大于鸭子.这时候你的机器已经基…<a href="/question/32246256/answer/55251597" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-5097916"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>9 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='6'><meta itemprop="answer-id" content="7661612" /><meta itemprop="answerCount" content="54" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/24095027">在进行线性回归时，为什么最小二乘法是最优方法？</a></h2><div class="entry-body "data-aid="7661612"data-atoken="30692610"data-collapsed="False"data-created="1411019228"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="161">161</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">161</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="161"><span class="voters"><span class="user-block"><a data-tip="p$t$xin-shi-yun" href="http://www.zhihu.com/people/xin-shi-yun" class="zg-link" title="信诗云">信诗云</a>、</span><span class="user-block"><a data-tip="p$t$hai-ru-xian" href="http://www.zhihu.com/people/hai-ru-xian" class="zg-link" title="夏奈">夏奈</a>、</span><span class="user-block"><a data-tip="p$t$littlesue" href="http://www.zhihu.com/people/littlesue" class="zg-link" title="苏暖暖">苏暖暖</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1819806" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/24095027/answer/30692610"><textarea class="content hidden">谢邀。&lt;br&gt;不是很同意 &lt;a data-hash=&quot;3f3539e4d4189d4a95e0f096d262a5f7&quot; href=&quot;//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@王芊&quot; data-tip=&quot;p$b$3f3539e4d4189d4a95e0f096d262a5f7&quot;&gt;@王芊&lt;/a&gt;的说法。&lt;br&gt;首先跟题主说一下，最小二乘法的“最优”也要看应用情景的。&lt;br&gt;实际上最小二乘法更准确的说是一个正交投影（orthogonal projection），而这个投影的很多优良性质不需要假设正态分布。&lt;br&gt;这里正交投影的意思是，在x所张成的线性空间里面找一个向量使得其与y的距离最小。&lt;br&gt;即使没有正态分布的假设，OLS也是对conditional expectation的最优线性预测。&lt;br&gt;也有人提到了BLUE，回想一下，证明BLUE的时候我们并没有用正态分布的假定。&lt;br&gt;如果从统计推断角度来说，小样本情况下的统计推断还需要正态的假设，大样本是不需要的。&lt;br&gt;最小二乘之所以是“最优”，仅仅是因为用这个方法做出来的刚好是正交投影而已。&lt;br&gt;但是还有很多其他方法，比如中位数回归：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Cmin_%5Cbeta%7B%5Csum_%7Bi%3D1%7D%5EN%7B%7Cy_i-x_i%27%5Cbeta%7C%7D%7D&quot; alt=&quot;\min_\beta{\sum_{i=1}^N{|y_i-x_i'\beta|}}&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;最小化的就是绝对值。而且中位数回归在某些方面有比最小二乘更好的性质，比如对异常值稳健等等。当然，如果误差分布对称，中位数回归的&lt;img src=&quot;//zhihu.com/equation?tex=%5Cbeta&quot; alt=&quot;\beta&quot; eeimg=&quot;1&quot;&gt;跟最小二乘得到的结果是渐进相等的。&lt;br&gt;感兴趣可以看一下这篇文章：&lt;a href=&quot;http://www.jstor.org/stable/2727353&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;JSTOR: Journal of Economic Literature, Vol. 29, No. 1 (Mar., 1991), pp. 34-50&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;还是那句话， 都在做回归，但是首先你得明确自己做回归的目的才能找到那个“最优”的回归方法。&lt;br&gt;=====&lt;br&gt;更新。&lt;br&gt;关于这个问题跟不同的人包括 &lt;a data-hash=&quot;3f3539e4d4189d4a95e0f096d262a5f7&quot; href=&quot;//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@王芊&quot; data-tip=&quot;p$b$3f3539e4d4189d4a95e0f096d262a5f7&quot;&gt;@王芊&lt;/a&gt;&lt;a data-hash=&quot;4069470ff2ed211620d6447410938f4c&quot; href=&quot;//www.zhihu.com/people/4069470ff2ed211620d6447410938f4c&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@SlowMover&quot; data-tip=&quot;p$b$4069470ff2ed211620d6447410938f4c&quot;&gt;@SlowMover&lt;/a&gt;&lt;a data-hash=&quot;e72e510186fa8a42e72073facaecfe10&quot; href=&quot;//www.zhihu.com/people/e72e510186fa8a42e72073facaecfe10&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@W Xue&quot; data-tip=&quot;p$b$e72e510186fa8a42e72073facaecfe10&quot;&gt;@W Xue&lt;/a&gt;&lt;a data-hash=&quot;55d6be5880ba6f3e258d5dba46cb24a9&quot; href=&quot;//www.zhihu.com/people/55d6be5880ba6f3e258d5dba46cb24a9&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@马拉轰&quot; data-tip=&quot;p$b$55d6be5880ba6f3e258d5dba46cb24a9&quot;&gt;@马拉轰&lt;/a&gt; 交流了一下，其实不同专业的人都在用OLS，但是不同专业的人对OLS的理解是完全不一样的。比如在计量经济学里面，至少有四五种方法可以得到OLS的结果，包括但不限于MLE、投影、GMM、最小化距离等。看到 &lt;a data-hash=&quot;3f3539e4d4189d4a95e0f096d262a5f7&quot; href=&quot;//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@王芊&quot; data-tip=&quot;p$b$3f3539e4d4189d4a95e0f096d262a5f7&quot;&gt;@王芊&lt;/a&gt; 的答案下面还有讨论稀疏性的，在计量经济学里面是完全不讨论的（或者是我不知道）。还有 &lt;a data-hash=&quot;e72e510186fa8a42e72073facaecfe10&quot; href=&quot;//www.zhihu.com/people/e72e510186fa8a42e72073facaecfe10&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@W Xue&quot; data-tip=&quot;p$b$e72e510186fa8a42e72073facaecfe10&quot;&gt;@W Xue&lt;/a&gt;的答案里面提到的物理意义，我表示也不能理解。&lt;br&gt;所以呢，这种问题答案很开放的，题主应该首先明确自己使用OLS的目的，是解释还是预测还是拟合曲线抑或是其他，你要的是系数还是预测值？使用目的的差异会导致同一种方法的理解和使用相去甚远。&lt;br&gt;不管怎样，希望大家看一下其他几位的答案，收获会很多。很开心跟大家进行这样的交流。之前 &lt;a data-hash=&quot;55d6be5880ba6f3e258d5dba46cb24a9&quot; href=&quot;//www.zhihu.com/people/55d6be5880ba6f3e258d5dba46cb24a9&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@马拉轰&quot; data-tip=&quot;p$b$55d6be5880ba6f3e258d5dba46cb24a9&quot;&gt;@马拉轰&lt;/a&gt; 又把我之前的一次争论拿出来说事，你看我们交流的不是很好么？好的态度应该是求同存异，而不是在不了解别人的专业的情况下妄自对别人进行攻击。看一下那个帖子对我攻击的人数和对我赞同的人数比较一下，应该知道那个帖子我之所以反应剧烈，是被一小部分自以为是的人逼的。&lt;br&gt;======&lt;br&gt;此外回答 &lt;a data-hash=&quot;3f3539e4d4189d4a95e0f096d262a5f7&quot; href=&quot;//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@王芊&quot; data-tip=&quot;p$b$3f3539e4d4189d4a95e0f096d262a5f7&quot;&gt;@王芊&lt;/a&gt;为什么要用欧氏距离而不是其他距离。有很多人回答了诸如简单、符合直觉、有显示解，我想最根本的还是因为“正交投影”四个字。优秀的性质并不是因为最小化了距离，而是&lt;b&gt;正交&lt;/b&gt;。这也就是 &lt;a data-hash=&quot;4069470ff2ed211620d6447410938f4c&quot; href=&quot;//www.zhihu.com/people/4069470ff2ed211620d6447410938f4c&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@SlowMover&quot; data-tip=&quot;p$b$4069470ff2ed211620d6447410938f4c&quot;&gt;@SlowMover&lt;/a&gt;提到Frisch-Waugh-Lovell定理的原因。如果说正交，必然先定义内积。有了内积，很多事情就变得方便了。其他的距离也可以用，但是不能保证正交，因为可能找不到一个导出这个距离的内积定义。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-09-18" target="_blank" href="/question/24095027/answer/30692610">编辑于 2014-09-21</a></span></textarea><div class="zh-summary summary clearfix">谢邀。不是很同意 <a data-hash="3f3539e4d4189d4a95e0f096d262a5f7" href="//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7" class="member_mention" data-editable="true" data-title="@王芊" data-tip="p$b$3f3539e4d4189d4a95e0f096d262a5f7">@王芊</a>的说法。首先跟题主说一下，最小二乘法的“最优”也要看应用情景的。实际上最小二乘法更准确的说是一个正交投影（orthogonal projection），而这个投影的很多优良性质不需要假设正态分布。这里正交投影的意思是，在x所张成的线性空间…<a href="/question/24095027/answer/30692610" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1819806"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>45 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine first-combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='7'><meta itemprop="answer-id" content="5333430" /><meta itemprop="answerCount" content="17" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/22935472">线性回归中的 ANOVA 的作用是什么？</a></h2><div class="entry-body "data-aid="5333430"data-atoken="25100683"data-collapsed="False"data-created="1398876014"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="137">137</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">137</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="137"><span class="voters"><span class="user-block"><a data-tip="p$t$xin-hao-92" href="http://www.zhihu.com/people/xin-hao-92" class="zg-link" title="xin hao">xin hao</a>、</span><span class="user-block"><a data-tip="p$t$pang-zi-63-73" href="http://www.zhihu.com/people/pang-zi-63-73" class="zg-link" title="胡胖子">胡胖子</a>、</span><span class="user-block"><a data-tip="p$t$wang-meng-ying-46-4" href="http://www.zhihu.com/people/wang-meng-ying-46-4" class="zg-link" title="王梦莹">王梦莹</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1355009" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/22935472/answer/25100683"><textarea class="content hidden">为啥还有这么多学统计的人来反驳我的答案？你们不翻一下答案，反对我的都是学统计的，学计量的一个也没有吱声。我下面列举的这些都是仔细学过高级（微观）计量的人的共识。不同领域处理方法不一样，我已经补充了，争论下去实在没有必要。&lt;br&gt;&lt;b&gt;题主一开始把这个问题只归了两类，“计量经济学”和“数学”好吗？压根没有归到“统计学”这一类。就好象我知道我的统计学知识不够不去统计板块答题一样，希望学统计的不要在不了解计量经济学的前提下妄自回答计量经济学的问题。&lt;/b&gt;&lt;br&gt;&lt;b&gt;你们看一下题主的问题是，“&lt;/b&gt;做线性回归的时候，回归结果中都会包含ANOVA的分析&lt;b&gt;”,在做线性回归的时候啊！他问的是线性回归结果里面那张ANOVA表好吗？你们学统计的一个个煞有介事的介绍ANOVA的应用是闹哪样。&lt;/b&gt;&lt;br&gt;要说统计，虽然我不是统计的phd，但是学计量的基础就是统计。谁不是从实分析 泛函分析 概率 统计一点一点读上来的？不要以为学计量的人都是土鳖好不，说过了，解决的问题不一样，处理方法不一样，仅此而已。&lt;br&gt;最后一次修改，懂的自然懂，反正我也没有必要也没有任何激励去给你们学统计的宣传计量的最新进展。&lt;br&gt;===================================&lt;br&gt;&lt;b&gt;特别声明，本人以下回答只针对计量经济学领域！&lt;/b&gt;我看到题主没有把统计学放到分类里面，只有计量经济学才敢于这么回答的。统计我懂的只是皮毛，但是要说计量～&lt;br&gt;其实很多人对计量经济学的理解还是统计学在经济学中的应用。为什么统计学在心理学、社会学上都有应用，偏偏没发展出计量心理学、计量社会学？有计量史学(cliometrics)，但是计量史学还都是计量经济学的应用。&lt;br&gt;因为阿，计量经济学跟统计学技术手段类似，但是解决的问题是不一样的。计量经济学更注重&lt;b&gt;解释&lt;/b&gt;，而非预测；计量经济学更关注&lt;b&gt;因果&lt;/b&gt;，而非相关；计量经济学更关注经济理论，&lt;b&gt;是用数据match理论&lt;/b&gt;，而非用数据&lt;u&gt;发现&lt;/u&gt;理论。&lt;br&gt;所以在最开始的时候，经常听说有统计学家和计量经济学家没办法交流。为什么？因为解决的问题不一样，其技术手段也不一样。比如 &lt;a data-hash=&quot;a67fba6153733372ff4ef53a909dee0d&quot; href=&quot;//www.zhihu.com/people/a67fba6153733372ff4ef53a909dee0d&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@TJ Zhou&quot; data-tip=&quot;p$b$a67fba6153733372ff4ef53a909dee0d&quot;&gt;@TJ Zhou&lt;/a&gt;对我的反驳，你们好好看看评论里面我们的讨论就知道，我们看似都在讨论线性回归，但是讨论的问题根本不是一个问题。&lt;br&gt;我为什么说R2不重要？不只是我说，计量领域的懂一点的都这么说。为什么？&lt;b&gt;因为R2很大程度上度量的是u的方差跟x的方差大小的问题。但是计量领域绝大多数情况下根本不关心你的u的方差有多大好吗？有更直接的指标看x对y的影响，干嘛还要看R2呢？&lt;/b&gt;&lt;br&gt;当然现在是有很多做统计的转而做计量经济学，其实也是用统计的方法解决经济的问题，并不是说计量经济学就是统计的分支了，计量经济学是经济学好吗？&lt;br&gt;记得前段时间有个国际著名计量经济学家，之前是某统计学院院长，在学院大会上说了一句“在我是个统计学家之前，我是个经济学家。”结果统计学院一大堆人都在吐槽这句话。计量经济学跟统计学的差别可见一斑了。&lt;br&gt;烦请反驳我的 &lt;a data-hash=&quot;a67fba6153733372ff4ef53a909dee0d&quot; href=&quot;//www.zhihu.com/people/a67fba6153733372ff4ef53a909dee0d&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@TJ Zhou&quot; data-tip=&quot;p$b$a67fba6153733372ff4ef53a909dee0d&quot;&gt;@TJ Zhou&lt;/a&gt;还有那位觉着我没有深入理解统计方法的 &lt;a data-hash=&quot;cb0deb07e13746b9e662ac6da1f06397&quot; href=&quot;//www.zhihu.com/people/cb0deb07e13746b9e662ac6da1f06397&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@赵卿元&quot; data-tip=&quot;p$b$cb0deb07e13746b9e662ac6da1f06397&quot;&gt;@赵卿元&lt;/a&gt;同学仔细看看我的回答。我如果在这个方面没有一点底气和信心，敢说这么绝对的话？敢专门发个专栏说R2在计量里面不重要？我找骂是不是？&lt;br&gt;还有那个 &lt;a data-hash=&quot;2188b74f885d03a93a68409e158ccab7&quot; href=&quot;//www.zhihu.com/people/2188b74f885d03a93a68409e158ccab7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@斯逸卿&quot; data-tip=&quot;p$b$2188b74f885d03a93a68409e158ccab7&quot;&gt;@斯逸卿&lt;/a&gt; 的“&lt;u&gt;如果y对a、b、c、d回归，系数都显著。这个显著只是在统计意义上显著，可能经济意义上不显著，表现为R方的增量很小&lt;/u&gt;。”导致R方增量很小的原因很有可能是你增加的d相对于u来说本身就没有多少variation，归根结底还是要看u的variance。当然你说预测可以理解了，但是经济学上d明明可以解释y，你忽略它就不对了吗！&lt;br&gt;=================================&lt;br&gt;分解方差。&lt;br&gt;现在很少有人看这个了。&lt;br&gt;方差分析跟R2一样，对你的模型的解释能力几乎没有任何参考意义。&lt;br&gt;===================&lt;br&gt;回答评论里面的问题，答案是没有什么能评估模型的解释能力。&lt;br&gt;先说R2为什么不可以。&lt;br&gt;我们假设一个最简单的数据生成过程(DGP)，y=x*b+u，其中x~N(0,1)，b=1，u~N(0,1)。这个时候你可以做出0.5的R2。但是如果u~N(0,2)，那么你只能做出0.25的R2。但是这两个DGP仅仅是误差项的方差改变了而已，我们关注的是b不是吗？就算R2小到只有0.0001，也许只是u的方差太大了，但是x对y还是有解释能力的对不对？而且解释能力跟R2无关。&lt;br&gt;方差分析有同样的问题。组内的方差其实就是误差项啊～&lt;br&gt;看一个模型的解释能力，要看的东西很多，但是没有一甚至几个假设检验或者指标可以直接看出来。计量经济学模型也是依赖假设的，关注一下现实的问题，看看你建立的模型跟现实是否符合才能看出模型是不是有解释能力。&lt;br&gt;比如你要问一下，识别是不是清楚？有没有内生性？做probit的时候有没有异方差？有没有sample selection的问题？有没有其他机制可以导致你做出来的回归结果？如果你做GMM，你的矩条件是否合理？等等等等。&lt;br&gt;所以，看模型解释能力看什么？看现实问题。&lt;br&gt;==============================&lt;br&gt;其实要说没用，还是有用的，看的人只是很少，不是没有。&lt;br&gt;比如当你研究歧视的时候，男女的工资差异可以分为两部分，一部分是你观察到的男女的差别，比如教育等，还有一部分就是误差项了。&lt;br&gt;在这个背景下，比较观察到的组间方差和观察不到的组内方差是有意义的。&lt;br&gt;================================&lt;br&gt;哇塞！斯坦佛的phd &lt;a data-hash=&quot;cb0deb07e13746b9e662ac6da1f06397&quot; href=&quot;//www.zhihu.com/people/cb0deb07e13746b9e662ac6da1f06397&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@赵卿元&quot; data-tip=&quot;p$b$cb0deb07e13746b9e662ac6da1f06397&quot;&gt;@赵卿元&lt;/a&gt; 都来反驳我唉！ &lt;br&gt;其实吧，这个问题就是计量跟统计的差别，计量关注因果，统计关注相关。计量关注统计量是不是显著，而不是这个模型的拟合程度（R2），这个是最关键的差别。要不然R2最高的方法就是OLS，还要发明工具变量、面板固定、随机效应、联立方程什么的模型干嘛？&lt;br&gt;经济学家不是不关注误差项。&lt;b&gt;在计量经济学家看来，误差项的方差是多少并不重要，重要的是你的误差项里面有什么。&lt;/b&gt;你的误差项方差再大，如果不是系统性的误差，不影响你的x的外生性，爱怎么大怎么大，系数显著就好。但是如果你的误差项里面有系统性的误差，你的误差项方差再小，你的模型也是错的，你估计出来的系数完全不是你想要的东西。在这种情况下，你甚至说不清楚你估计出来的是什么东西～&lt;br&gt;还有，ANOVA其实就是特殊情况下的OLS模型，上面我举例子了，经济学也有可能用到ANOVA，我没说这个东西绝对没用，只是在计量领域，用处不大~至于我有没有用过ANOVA，只有我自己知道～&lt;br&gt;============================&lt;br&gt;顺便吐槽一下吧，改天修改一下发到我的专栏里去。&lt;br&gt;&lt;b&gt;计量经济学中那些从统计学、初级计量里面带来的恶习&lt;/b&gt;&lt;br&gt;1、随意删变量&lt;br&gt;什么？某个变量不显著？删掉！呵呵～这个变量如果理论上对你的y有影响，但是做不出显著，一可能是你的模型错了，二可能是数据没有足够的variation做出显著。如果删掉，你其他的估计都会受到“遗漏变量”的影响，估计的系数理论上都不对的～&lt;br&gt;2、多重共线性&lt;br&gt;这个多少跟第一条有关系。什么？你的模型有多重共线性？好严重啊！删变量吧！&lt;br&gt;为什么不能删变量第一条已经说了。&lt;br&gt;解决多重共线性最好的办法是增加样本，别的好像没办法了。&lt;br&gt;至于有人用“主成份分析法”，呵呵，你还知道你估计的东西是啥不？&lt;br&gt;3、变量筛选&lt;br&gt;也跟第一条有关系，做很多很多回归，把显著的变量留下来，不显著的删掉。不解释了，参见第一条。&lt;br&gt;4、异方差&lt;br&gt;都21世纪了，你还在线性模型里面检验异方差？没听说过white heteroskedasticity robust的统计量吗？这个还需要检验？还需要加权最小二乘？&lt;br&gt;只有非线性模型中异方差是致命的，线性模型中异方差可以很方便的用white或者Newey-west来解决。&lt;br&gt;5、R2&lt;br&gt;这个多少跟主题有关。实际情况是，时间序列你做出低于90%的R2都不正常，但是微观数据你做出50%的R2都很困难。&lt;br&gt;OLS是在给定的数据和变量条件下R2最高的，因为他是个线性投影。工具变量估计是一个非正交投影，所以R2肯定比OLS的要低。但是我们还是要发展IV之类的方法，这也从侧面反映了R2不重要。&lt;br&gt;所以你如果用R2去比较模型，完全没有意义。&lt;br&gt;6、Box-Jenkins&lt;br&gt;不是专业做时间序列的，不做过多评价。但是基于ACF、PACF图的什么“截尾”、“拖尾”是很不靠谱的方法，已经是共识了。&lt;br&gt;==========================&lt;br&gt;&lt;u&gt;这篇回答只限内部讨论，请知乎的小编不要再把这篇发到微博上去了。里面有八卦，不想传开，如果小编感兴趣，去转专栏里面的文章吧。p.s. 上次你们在微博上推我的文章，曲解我的意思好不好！以后你们公开推别人的回答，可不可以征询一下作者的意见！&lt;/u&gt;<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-05-01" target="_blank" href="/question/22935472/answer/25100683">编辑于 2014-05-04</a></span></textarea><div class="zh-summary summary clearfix">为啥还有这么多学统计的人来反驳我的答案？你们不翻一下答案，反对我的都是学统计的，学计量的一个也没有吱声。我下面列举的这些都是仔细学过高级（微观）计量的人的共识。不同领域处理方法不一样，我已经补充了，争论下去实在没有必要。<b>题主一开始把这个问…</b><a href="/question/22935472/answer/25100683" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1355009"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>121 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='8'><meta itemprop="answer-id" content="5344468" /><meta itemprop="answerCount" content="17" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/22935472">线性回归中的 ANOVA 的作用是什么？</a></h2><div class="entry-body "data-aid="5344468"data-atoken="25128207"data-collapsed="False"data-created="1398965551"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="100">100</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">100</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$zhao-qing-yuan-78" href="/people/zhao-qing-yuan-78">赵卿元</a>，<span title="统计学" class="bio">统计学</span></div><div class="zm-item-vote-info " data-votecount="100"><span class="voters"><span class="user-block"><a data-tip="p$t$liao-zhou-yi" href="http://www.zhihu.com/people/liao-zhou-yi" class="zg-link" title="廖洲艺">廖洲艺</a>、</span><span class="user-block"><a data-tip="p$t$paloalto" href="http://www.zhihu.com/people/paloalto" class="zg-link" title="Palo Alto">Palo Alto</a>、</span><span class="user-block"><a data-tip="p$t$yang-yu-hao-95" href="http://www.zhihu.com/people/yang-yu-hao-95" class="zg-link" title="逆寒vees">逆寒vees</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1355009" data-action="/answer/content" data-author-name="赵卿元" data-entry-url="/question/22935472/answer/25128207"><textarea class="content hidden">统计学最大的问题是应用统计方法的人只是会用，远谈不上有深入的理解。题主也许在计量经济学中学到了回归和方差分析，甚至会以为这些只是计量经济学的一部分；高票答主也是搞计量的，可能都没怎么用过ANOVA，想当然的就觉得没用了。&lt;br&gt;&lt;br&gt;不管你用什么方法，统计学家都会提供给你很多统计量，有的用来估计模型参数，有的用来检验假设，有的用来判断模型本身的正确性。应用过程中要特别清楚每个数字背后是什么含义，怎么解释。R^2估计的是模型的解释能力，但并不能用来判断回归系数是否显著；方差分析中的p value可以用来判断系数显著，又不能推断关系是否为线性。&lt;br&gt;&lt;br&gt;回到题主的问题。ANOVA可以看作是一种特殊的linear model。在covariate都是factor的时候（如性别，治疗/对照），统计学家发现线性模型有一种更简单好用的形式--方差分解。你在用线性模型时看到的表并不一定是ANOVA table，那个表讲的是每个covariate的显著性。如果covariate是factor，那么每一行就是一个factor的一个leve。&lt;br&gt;&lt;br&gt;============================&lt;br&gt;回答@Jichun Si :&lt;br&gt;你的一个误区是认为只有计量经济学关心模型的解释能力和因果关系。实际上统计学家对此的重视绝不可能更少，统计学早期发展中反复讨论的一个问题是吸烟和肺癌的因果关系，ANOVA被发明的动机也是研究影响农产品产量的因素，当前研究热点高维统计也是围绕模型的interpretability。只关心模型预测能力的统计学家只是极少数。&lt;br&gt;这道问题被统计学家攻占的显然原因是题目中的线性回归和ANOVA都是最基本的统计工具，在各种领域都有广泛应用。我希望题主和读者都能跳出它们在计量经济学中的应用来看待这些统计方法。例如你说的R^2在计量经济学中意义不大，但在一个一般的问题中，它还是衡量模型好坏的一个好用易解释的指标，不可妄下结论。&lt;br&gt;============================<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-05-02" target="_blank" href="/question/22935472/answer/25128207">编辑于 2014-05-04</a></span></textarea><div class="zh-summary summary clearfix">统计学最大的问题是应用统计方法的人只是会用，远谈不上有深入的理解。题主也许在计量经济学中学到了回归和方差分析，甚至会以为这些只是计量经济学的一部分；高票答主也是搞计量的，可能都没怎么用过ANOVA，想当然的就觉得没用了。不管你用什么方法，统计…<a href="/question/22935472/answer/25128207" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1355009"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>32 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='9'><meta itemprop="answer-id" content="7689397" /><meta itemprop="answerCount" content="54" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/24095027">在进行线性回归时，为什么最小二乘法是最优方法？</a></h2><div class="entry-body "data-aid="7689397"data-atoken="30762001"data-collapsed="False"data-created="1411140293"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="80">80</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">80</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$zhi-zhi-qi-di" href="/people/zhi-zhi-qi-di">AlWeis</a>，<span title="Marie Curie Experienced Researcher" class="bio">Marie Curie Experienced Researcher</span></div><div class="zm-item-vote-info " data-votecount="80"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$hai-ru-xian" href="http://www.zhihu.com/people/hai-ru-xian" class="zg-link" title="夏奈">夏奈</a>、</span><span class="user-block"><a data-tip="p$t$littlesue" href="http://www.zhihu.com/people/littlesue" class="zg-link" title="苏暖暖">苏暖暖</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1819806" data-action="/answer/content" data-author-name="AlWeis" data-entry-url="/question/24095027/answer/30762001"><textarea class="content hidden">同意 &lt;a data-hash=&quot;c9cee996cde274145f8f11fc15404768&quot; href=&quot;//www.zhihu.com/people/c9cee996cde274145f8f11fc15404768&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@Jichun Si&quot; data-tip=&quot;p$b$c9cee996cde274145f8f11fc15404768&quot;&gt;@Jichun Si&lt;/a&gt; 不太同意 &lt;a data-hash=&quot;3f3539e4d4189d4a95e0f096d262a5f7&quot; href=&quot;//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@王芊&quot; data-tip=&quot;p$b$3f3539e4d4189d4a95e0f096d262a5f7&quot;&gt;@王芊&lt;/a&gt;的说法。&lt;br&gt;&lt;br&gt;Andrew Ng的推导应该只是说明了，在Gaussian噪声的假设下，最大似然可以推导出最小二乘，仅此而已，个人认为并没有说明最小二乘的必要性。&lt;br&gt;&lt;br&gt;最小二乘是&lt;b&gt;在欧氏距离为误差度量的情况下&lt;/b&gt;，由系数矩阵所张成的向量空间内对于观测向量的最佳逼近点。&lt;br&gt;&lt;br&gt;为什么用欧式距离作为误差度量 （即MSE），09年IEEE Signal Processing Magzine 的 《Mean squared error: Love it or leave it?》这篇文章做了很好的讨论。链接：&lt;a href=&quot;http://www2.units.it/ramponi/teaching/DIP/materiale/mse_bovik09.pdf&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;www2.units.it/ramponi/t&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;eaching/DIP/materiale/mse_bovik09.pdf&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;这篇文章在&quot;WHY DO WE LOVE THE MSE?&quot;中说，MSE：&lt;br&gt;&lt;ul&gt;&lt;li&gt;1. 它简单。&lt;br&gt;&lt;/li&gt;&lt;li&gt;2. 它提供了具有很好性质的相似度的度量。例如：&lt;br&gt;&lt;/li&gt;&lt;li&gt;     1）它是非负的;&lt;br&gt;&lt;/li&gt;&lt;li&gt;     2）唯一确定性。只有x=y的时候，d(x,y)=0；&lt;br&gt;&lt;/li&gt;&lt;li&gt;     3）它是对称的，即d(x,y)=d(y,x)；&lt;br&gt;&lt;/li&gt;&lt;li&gt;     4）符合三角性质。即d(x,z)&amp;lt;=d(x,y)+d(y,z).&lt;br&gt;&lt;/li&gt;&lt;li&gt;3. 物理性质明确，在不同的表示域变换后特性不变，例如帕萨瓦尔等式。&lt;br&gt;&lt;/li&gt;&lt;li&gt;4. 便于计算。通常所推导得到的问题是凸问题，具有对称性，可导性。通常具有解析解，此外便于通过迭代的方式求解。&lt;br&gt;&lt;/li&gt;&lt;li&gt;5. 和统计和估计理论具有关联。在某些假设下，统计意义上是最优的。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;然而，&lt;b&gt;MSE并非没有缺点&lt;/b&gt;。并不是所有的问题都可以套用该准则，在“IMPLICIT ASSUMPTIONS WHEN USING THE MSE”说，它基于了以下几点对于信号的假设：&lt;br&gt;&lt;ul&gt;&lt;li&gt;1. 信号的保真度和该信号的空间和时间顺序无关。即，以同样的方法，改变两个待比较的信号本身的空间或时间排列，它们之间的误差不变。例如，[1 2 3], [3 4 5]两组信号的MSE和[3 2 1],[5 4 3]的MSE一样。&lt;br&gt;&lt;/li&gt;&lt;li&gt;2. 误差信号和原信号无关。只要误差信号不变，无论原信号如何，MSE均不变。例如，对于固定误差[1 1 1]，无论加在[1 2 3]产生[2 3 4]还是加在[0 0 0]产生[1 1 1]，MSE的计算结果不变。&lt;br&gt;&lt;/li&gt;&lt;li&gt;3. 信号的保真度和误差的符号无关。即对于信号[0 0 0]，与之相比较的两个信号[1 2 3]和[-1 -2 -3]被认为和[0 0 0]具有同样的差别。&lt;br&gt;&lt;/li&gt;&lt;li&gt;4. 信号的不同采样点对于信号的保真度具有同样的重要性。&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;本文后面还讨论了MSE对于图像和语音这些具有空间和时间信息的信号来说，并非就是完美的，并举了不少例子。有兴趣的可以下下来论文自己看。对于本问题来说，我觉得这些讨论已经够了。<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/24095027/answer/30762001">发布于 2014-09-19</a></span></textarea><div class="zh-summary summary clearfix">同意 <a data-hash="c9cee996cde274145f8f11fc15404768" href="//www.zhihu.com/people/c9cee996cde274145f8f11fc15404768" class="member_mention" data-editable="true" data-title="@Jichun Si" data-tip="p$b$c9cee996cde274145f8f11fc15404768">@Jichun Si</a> 不太同意 <a data-hash="3f3539e4d4189d4a95e0f096d262a5f7" href="//www.zhihu.com/people/3f3539e4d4189d4a95e0f096d262a5f7" class="member_mention" data-editable="true" data-title="@王芊" data-tip="p$b$3f3539e4d4189d4a95e0f096d262a5f7">@王芊</a>的说法。Andrew Ng的推导应该只是说明了，在Gaussian噪声的假设下，最大似然可以推导出最小二乘，仅此而已，个人认为并没有说明最小二乘的必要性。最小二乘是<b>在欧氏距离为误差度量的情况下</b>，由系数矩阵所张成的向量空间内对…<a href="/question/24095027/answer/30762001" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1819806"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>14 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='10'><meta itemprop="answer-id" content="3190568" /><meta itemprop="answerCount" content="4" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/22007264">如何通俗地解释贝叶斯线性回归的基本原理？</a></h2><div class="entry-body "data-aid="3190568"data-atoken="20014371"data-collapsed="False"data-created="1384188513"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="37">37</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">37</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$wenzhe-li" href="/people/wenzhe-li">李文哲</a>，<span title="PhD@USC, Chief Scientist@puhuifinance, 长期招聘" class="bio">PhD@USC, Chief Scientist@puhuifinance,…</span></div><div class="zm-item-vote-info " data-votecount="37"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block">知乎用户、</span><span class="user-block">知乎用户</span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="983852" data-action="/answer/content" data-author-name="李文哲" data-entry-url="/question/22007264/answer/20014371"><textarea class="content hidden">并不仅仅加了先验p(w), 有很大的区别。 任何的一个基础模型都可以演变成贝叶斯模型。在一个基础模型之下我们需要去estimate一些未知的参数（比如在linear regression, 需要去计算W这个向量）， 但在贝叶斯模型下我们需要去计算的是W的分布（而不是W的point estimation)，用其分布直接计算对y的预测值p(y|x,D)，所以我们需要去需要integrate W，也就是说我们把所有可能的W向量都会去考虑， 这也为什么贝叶斯模型通常intractable, 所以我们需要用MCMC或者variational方法，而不是直接用优化的方法。在贝叶斯模型之下， 随着我们observe more and more data , 我们会对W向量的分布会有更清晰的推断，这其实就是posterior inference. &lt;br&gt;&lt;br&gt;下面简单说一下一些预测模型之间的联系：&lt;br&gt;我们一般考虑3种预测模式，Maximum likelihood estimation (ML), Maximum a posteriori estimation（MAP)， 贝叶斯模型.  前两者属于point estimation. &lt;br&gt;&lt;br&gt;&lt;b&gt;Maximum likelihood estimation (ML):&lt;/b&gt; 这是最简单的point estimation,  也就是我们需要去计算P(D|W), 从而找到最优化的W. 它的缺点就是数据比较少的时候往往overfit。&lt;br&gt;&lt;br&gt;&lt;b&gt;Maximum a posteriori estimation (MAP)&lt;/b&gt;. 他是在ML的基础上加了prior, 也就是假定了一些P(W)的分布。在MAP情况下我们需要计算P(W|D) (从贝叶斯定理，我们可以得到 P(W|D) \prop P(W) \times P(D|W)).  在linear regression上加上prior其实相当于加了regularization. 如果我们假定P(W)服从高斯分布，那我们加的实际上是L2_norm, 如果我们假定P(W)是拉普拉斯分布，那我们加的是L1_norm(linear regression情况下就是相当于LASSO，会有sparse的特点）。 但是即使regularization会防止overfitting, 但我们还是需要设置regularization coefficient \lamda （比如 minimize \sum_i (y_i-f(_ix,w))^2 + \lamda ||w||_2^2).  lamda的设置一般需要用cross validation,或者用一些统计学的方法（尽管实际上没有多少人用这个）， 所以在MAP的情况下设置这些regularization coefficient成了难题。 &lt;br&gt;&lt;br&gt;&lt;b&gt;贝叶斯模型&lt;/b&gt;：&lt;br&gt;好了，MAP的一些limitation 贝叶斯可以帮我们解决. 贝叶斯的特点就是考虑整个W的分布，所以自然而然也就是防止overfitting. 在贝叶斯模型下，我们需要计算P(W|D), 但不要忘记，在这里我们是计算W的分布，而不是W的一个最优化的值！（不同于MAP)。 当然，贝叶斯的优点也带来了一些麻烦，就是它的计算比前两个方法复杂的多。如果想深入了解的话可以去翻翻MCMC或者variational inference文章读一读。&lt;br&gt;&lt;br&gt;Ideally, 如果我们的数据非常多， ML的效果已经很好了。 数据越多，我们的prior P(W)的作用会越小。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2013-11-12" target="_blank" href="/question/22007264/answer/20014371">编辑于 2014-12-12</a></span></textarea><div class="zh-summary summary clearfix">并不仅仅加了先验p(w), 有很大的区别。 任何的一个基础模型都可以演变成贝叶斯模型。在一个基础模型之下我们需要去estimate一些未知的参数（比如在linear regression, 需要去计算W这个向量）， 但在贝叶斯模型下我们需要去计算的是W的分布（而不是W的point …<a href="/question/22007264/answer/20014371" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-983852"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>5 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='11'><meta itemprop="answer-id" content="8127319" /><meta itemprop="answerCount" content="21" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/26001914">多元线性回归建模如何确定选择哪些解释变量？</a></h2><div class="entry-body "data-aid="8127319"data-atoken="31854442"data-collapsed="False"data-created="1413277354"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="27">27</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">27</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="27"><span class="voters"><span class="user-block"><a data-tip="p$t$qiu-lei-min" href="http://www.zhihu.com/people/qiu-lei-min" class="zg-link" title="UncleCharlie">UncleCharlie</a>、</span><span class="user-block"><a data-tip="p$t$li-wan-zi-51" href="http://www.zhihu.com/people/li-wan-zi-51" class="zg-link" title="李丸子">李丸子</a>、</span><span class="user-block"><a data-tip="p$t$sopheer-zhang" href="http://www.zhihu.com/people/sopheer-zhang" class="zg-link" title="sopheer Zhang">sopheer Zhang</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="2583698" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/26001914/answer/31854442"><textarea class="content hidden">对于那些没有理论指导的问题，做线性回归不要放在经济学、计量经济学这个分类里面。同 &lt;a data-hash=&quot;2266a171ce470564c5e8fcaad5c7668e&quot; href=&quot;//www.zhihu.com/people/2266a171ce470564c5e8fcaad5c7668e&quot; class=&quot;member_mention&quot; data-editable=&quot;true&quot; data-title=&quot;@卢晶亮&quot; data-tip=&quot;p$b$2266a171ce470564c5e8fcaad5c7668e&quot;&gt;@卢晶亮&lt;/a&gt; 所说，经济学做回归，放什么变量不放什么变量都是有原因的，该放的不放，不该放的乱放，都有问题。另外经济学里面，R方也说明不了什么问题。&lt;br&gt;没有理论，还是问问统计学家吧。&lt;br&gt;============&lt;br&gt;更新一下，有些答案看不过去了。。&lt;br&gt;说主成分分析什么的也就算了，还有说Logistic的。。。&lt;br&gt;多重共线性造成r2高？？？你发明的理论啊&lt;br&gt;为什么知乎上总是有不懂乱答的人<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-10-14" target="_blank" href="/question/26001914/answer/31854442">编辑于 2014-10-15</a></span></textarea><div class="zh-summary summary clearfix">对于那些没有理论指导的问题，做线性回归不要放在经济学、计量经济学这个分类里面。同 <a data-hash="2266a171ce470564c5e8fcaad5c7668e" href="//www.zhihu.com/people/2266a171ce470564c5e8fcaad5c7668e" class="member_mention" data-editable="true" data-title="@卢晶亮" data-tip="p$b$2266a171ce470564c5e8fcaad5c7668e">@卢晶亮</a> 所说，经济学做回归，放什么变量不放什么变量都是有原因的，该放的不放，不该放的乱放，都有问题。另外经济学里面，R方也说明不了什么问题。没有理论，还是问问…<a href="/question/26001914/answer/31854442" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-2583698"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>添加评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='12'><meta itemprop="answer-id" content="23349979" /><meta itemprop="answerCount" content="60" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/36845076">线性代数有什么用？学习线性代数的意义在哪？</a></h2><div class="entry-body "data-aid="23349979"data-atoken="69824271"data-collapsed="False"data-created="1446052097"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="21">21</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">21</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><span class="name">匿名用户</span></div><div class="zm-item-vote-info " data-votecount="21"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$li-long-pan" href="http://www.zhihu.com/people/li-long-pan" class="zg-link" title="李龙攀">李龙攀</a>、</span><span class="user-block"><a data-tip="p$t$xieyihan994" href="http://www.zhihu.com/people/xieyihan994" class="zg-link" title="小函儿喵">小函儿喵</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="6945257" data-action="/answer/content" data-author-name="匿名用户" data-entry-url="/question/36845076/answer/69824271"><textarea class="content hidden">“而今天计算机没什么不能算的”，正是因为有了线代，计算机才能算这么多。<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/36845076/answer/69824271">发布于 2015-10-29</a></span></textarea><div class="zh-summary summary clearfix">“而今天计算机没什么不能算的”，正是因为有了线代，计算机才能算这么多。</div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-6945257"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>3 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='13'><meta itemprop="answer-id" content="10953405" /><meta itemprop="answerCount" content="4" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/27974196">线性模型如何解决变量相关性问题？</a></h2><div class="entry-body "data-aid="10953405"data-atoken="38903764"data-collapsed="False"data-created="1423045809"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="17">17</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">17</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="17"><span class="voters"><span class="user-block"><a data-tip="p$t$santostang" href="http://www.zhihu.com/people/santostang" class="zg-link" title="唐松">唐松</a>、</span><span class="user-block"><a data-tip="p$t$weizier" href="http://www.zhihu.com/people/weizier" class="zg-link" title="weizier">weizier</a>、</span><span class="user-block">知乎用户</span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="3372344" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/27974196/answer/38903764"><textarea class="content hidden">谢 &lt;a data-hash=&quot;ace55bee53f65086ccd880bf9c94018e&quot; href=&quot;//www.zhihu.com/people/ace55bee53f65086ccd880bf9c94018e&quot; class=&quot;member_mention&quot; data-tip=&quot;p$b$ace55bee53f65086ccd880bf9c94018e&quot;&gt;@朱晋玄&lt;/a&gt;邀请。&lt;br&gt;这个问题已经是知乎上的老大难问题了。为什么成为老大难问题？因为不同的人做回归目的不一样，处理方法是完全不一样的。所以看到这个问题分在机器学习这个类别下，我不是很愿意回答，因为不了解他们究竟做回归为了做什么。不过我愿意从统计学的角度给一点思路。&lt;br&gt;首先要明确一点：&lt;b&gt;变量之间的相关性（只要不是完全相关）是不会影响参数的一致性的&lt;/b&gt;。&lt;br&gt;那么会影响什么呢？&lt;b&gt;影响的是参数估计的方差&lt;/b&gt;。&lt;br&gt;所以，如果你的样本足够大，变量间的相关性不是什么大问题，甚至压根就不是问题。&lt;br&gt;那么如果你的样本没那么大，该怎么处理呢？这个时候就要看你做模型的目的了。简单的区分的话，你究竟关注相关，还是因果，甚至只是想预测？&lt;br&gt;如果你是关注因果，那么不好意思，这个问题没有办法。比如如果在经济学里面，像 &lt;a data-hash=&quot;ace55bee53f65086ccd880bf9c94018e&quot; href=&quot;//www.zhihu.com/people/ace55bee53f65086ccd880bf9c94018e&quot; class=&quot;member_mention&quot; data-tip=&quot;p$b$ace55bee53f65086ccd880bf9c94018e&quot;&gt;@朱晋玄&lt;/a&gt;说的，&lt;b&gt;你如果删掉任何一个变量，都会导致遗漏变量而产生偏误，这个时候你的系数估计是不一致的&lt;/b&gt;。&lt;br&gt;如果仅仅是关注相关，那么主成分分析等是个好的方法。此外如果你觉着有一些系数应该为0，甚至还可以LASSO。&lt;br&gt;如果你是想预测，那么虽然多重共线性导致系数估计方差变大，但是预测能力不会有所降低，所以我觉着这个问题没有那么值得去处理。&lt;br&gt;&lt;br&gt;以上只是个大概，希望题主根据自己面临的现实问题好好思考一下。<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/27974196/answer/38903764">发布于 2015-02-04</a></span></textarea><div class="zh-summary summary clearfix">谢 <a data-hash="ace55bee53f65086ccd880bf9c94018e" href="//www.zhihu.com/people/ace55bee53f65086ccd880bf9c94018e" class="member_mention" data-tip="p$b$ace55bee53f65086ccd880bf9c94018e">@朱晋玄</a>邀请。这个问题已经是知乎上的老大难问题了。为什么成为老大难问题？因为不同的人做回归目的不一样，处理方法是完全不一样的。所以看到这个问题分在机器学习这个类别下，我不是很愿意回答，因为不了解他们究竟做回归为了做什么。不过我愿意从统计…<a href="/question/27974196/answer/38903764" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-3372344"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>10 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine first-combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='14'><meta itemprop="answer-id" content="5282827" /><meta itemprop="answerCount" content="3" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/23453503">如何简明地解释「线性回归」「贝叶斯定理」「假设检验」这些术语？</a></h2><div class="entry-body "data-aid="5282827"data-atoken="24975238"data-collapsed="False"data-created="1398596720"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="15">15</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">15</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><span class="name">知乎用户</span></div><div class="zm-item-vote-info " data-votecount="15"><span class="voters"><span class="user-block"><a data-tip="p$t$qia-qia-gao-66" href="http://www.zhihu.com/people/qia-qia-gao-66" class="zg-link" title="卡卡高">卡卡高</a>、</span><span class="user-block"><a data-tip="p$t$jia-zhen-yu" href="http://www.zhihu.com/people/jia-zhen-yu" class="zg-link" title="snow">snow</a>、</span><span class="user-block"><a data-tip="p$t$palatino-shi" href="http://www.zhihu.com/people/palatino-shi" class="zg-link" title="Ferax">Ferax</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1562707" data-action="/answer/content" data-author-name="刑无刀" data-entry-url="/question/23453503/answer/24975238"><textarea class="content hidden">&lt;a data-hash=&quot;d8b25f09b7b4d1eba0e9a13d66ad319b&quot; href=&quot;//www.zhihu.com/people/d8b25f09b7b4d1eba0e9a13d66ad319b&quot; class=&quot;member_mention&quot; data-tip=&quot;p$b$d8b25f09b7b4d1eba0e9a13d66ad319b&quot;&gt;@袁树仑&lt;/a&gt; 你老邀请我回答这类问题居心何在？！害我大周末不能安心看电影！&lt;br&gt;&lt;br&gt;我倒是经常尝试跟文科女解释这些东西，以检验是否能通俗解释。&lt;br&gt;&lt;br&gt;好，现在我就假想我要跟文科女解释这几个东西好了，说错了也不要苛责我啊，反正是给文科女解释的，能得到芳心就达到目的了，哇咔咔。。。&lt;br&gt;&lt;br&gt;【线性回归】&lt;br&gt;“越长大越孤单”，如果说年龄大一岁，孤单多一分的话，那这就是孤单和年龄线性回归。&lt;br&gt;【贝叶斯】&lt;br&gt;你原来有三观（先验），但是当你经历一些事后（观察），你的三观会被重新建立，或者被毁三观（后验）。&lt;br&gt;【假设检验】 &lt;br&gt;文科女说：不把工资卡交给老婆的男人有九成可能不会成功。&lt;br&gt;我要反驳她这句话，必须得先假设她是对的。然后再按照她的说法去观察周围的男人，交工资卡和成功的事实都如何，并且默默地记在自己的小本上。&lt;br&gt;如果她说的这句话是对的，那么我小本上记的结果就会很明显，否则的话，哼哼，我就不承认她这句话！<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-04-27" target="_blank" href="/question/23453503/answer/24975238">编辑于 2015-07-06</a></span></textarea><div class="zh-summary summary clearfix"><a data-hash="d8b25f09b7b4d1eba0e9a13d66ad319b" href="//www.zhihu.com/people/d8b25f09b7b4d1eba0e9a13d66ad319b" class="member_mention" data-tip="p$b$d8b25f09b7b4d1eba0e9a13d66ad319b">@袁树仑</a> 你老邀请我回答这类问题居心何在？！害我大周末不能安心看电影！我倒是经常尝试跟文科女解释这些东西，以检验是否能通俗解释。好，现在我就假想我要跟文科女解释这几个东西好了，说错了也不要苛责我啊，反正是给文科女解释的，能得到芳心就达到目的…<a href="/question/23453503/answer/24975238" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1562707"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>1 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='15'><meta itemprop="answer-id" content="5164882" /><meta itemprop="answerCount" content="3" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/23453503">如何简明地解释「线性回归」「贝叶斯定理」「假设检验」这些术语？</a></h2><div class="entry-body "data-aid="5164882"data-atoken="24696698"data-collapsed="False"data-created="1397923976"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="13">13</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">13</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$orangeprince" href="/people/orangeprince">Orangeprince</a>，<span title="http://orangeprince.info" class="bio"><a href="http://orangeprince.info" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">orangeprince.info</span><span class="invisible"></span><i class="icon-external"></i></a></span></div><div class="zm-item-vote-info " data-votecount="13"><span class="voters"><span class="user-block"><a data-tip="p$t$yexiaodang" href="http://www.zhihu.com/people/yexiaodang" class="zg-link" title="叶小党">叶小党</a>、</span><span class="user-block"><a data-tip="p$t$palatino-shi" href="http://www.zhihu.com/people/palatino-shi" class="zg-link" title="Ferax">Ferax</a>、</span><span class="user-block"><a data-tip="p$t$ou-yang-jie-90" href="http://www.zhihu.com/people/ou-yang-jie-90" class="zg-link" title="彭小漪">彭小漪</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1562707" data-action="/answer/content" data-author-name="Orangeprince" data-entry-url="/question/23453503/answer/24696698"><textarea class="content hidden">你的领导给你一个任务，去调查某个地方算不算美女多的地方。当然，你的领导有自己的美女判定标准，假设评价一个女子的好看程度有三个属性：脸蛋，身材，气质。&lt;br&gt;&lt;br&gt;首先他要给你一些例子，比如她觉得奶茶是美女，高圆圆长的一般，范冰冰长的不好看。从这些例子里面，你大概能知道你领导的审美标准，脸蛋、身材、气质这三个属性大概各占什么样的比例。这就是回归。如果我们最终的美丑得分是把这三个标准的结果线性相加，就是线性回归。&lt;br&gt;&lt;br&gt;现在你能够判断一个女子是否是美女。你来到这个地方，一连碰到5个女子，按之前的标准判断，全是美女，那么你会不会认为这个地方的女子全都是美女呢？一般来说不会。因为经验告诉你，任何地方都有美女和丑女，不太可能只能出现只有美女没有丑女的地方，这个就是先验。如果你按这种方式思考，你会认为这个地方可能美女的比例比较高，但不会认为这里的女子全是美女，这就是贝叶斯的思想。&lt;br&gt;&lt;br&gt;最后，你的领导目的是让你调查这个地方的美女多不多，那么多不多最终是要有一个标准的，而你又没有办法遍历当地的每一个女性。所以你肯定有一套方案，比如说随机访问100个女性，如果超过80个女性是美女，你就认为该地是一个美女多的地方，反之则不是。那么之前提到的方案可以看成是一个假设检验。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-04-20" target="_blank" href="/question/23453503/answer/24696698">编辑于 2014-04-20</a></span></textarea><div class="zh-summary summary clearfix">你的领导给你一个任务，去调查某个地方算不算美女多的地方。当然，你的领导有自己的美女判定标准，假设评价一个女子的好看程度有三个属性：脸蛋，身材，气质。首先他要给你一些例子，比如她觉得奶茶是美女，高圆圆长的一般，范冰冰长的不好看。从这些例子里…<a href="/question/23453503/answer/24696698" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1562707"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>3 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding combine" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='16'><meta itemprop="answer-id" content="5155250" /><meta itemprop="answerCount" content="3" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/23453503">如何简明地解释「线性回归」「贝叶斯定理」「假设检验」这些术语？</a></h2><div class="entry-body "data-aid="5155250"data-atoken="24676685"data-collapsed="False"data-created="1397883509"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="10">10</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">10</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$bihan-wen" href="/people/bihan-wen">Bihan Wen</a>，<span title="EE博士生，UIUC" class="bio">EE博士生，UIUC</span></div><div class="zm-item-vote-info " data-votecount="10"><span class="voters"><span class="user-block"><a data-tip="p$t$fanny-64" href="http://www.zhihu.com/people/fanny-64" class="zg-link" title="Fanny">Fanny</a>、</span><span class="user-block"><a data-tip="p$t$misei-ou" href="http://www.zhihu.com/people/misei-ou" class="zg-link" title="miruko">miruko</a>、</span><span class="user-block"><a data-tip="p$t$jinjinxx" href="http://www.zhihu.com/people/jinjinxx" class="zg-link" title="金金">金金</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="1562707" data-action="/answer/content" data-author-name="Bihan Wen" data-entry-url="/question/23453503/answer/24676685"><textarea class="content hidden">试着回答一下前两个&lt;br&gt;&lt;br&gt;1）线性回归（Linear Regression）：假设你在纸上画了一堆点，然后打算画一条线，这些点到这条线的距离尽量得短。怎么找这条线呢？方法就是Linear Regression。有了这条线，希望用它来预测之后出现的点都会在它附近。&lt;br&gt;&lt;br&gt;2）贝叶思（Bayes Theorem）：&lt;br&gt;假设说我知道(1)明天是下雨的机率是A，(2)明天打雷的机率是B，(3)如果明天下雨了，那么就会打雷的机率是C。那么Bayes表示，如果明天打雷，那么下雨的机率是C*A/B。概括来讲，就是描述如果X那么Y的机率，和如果Y那么X的机率之间的转换关系。&lt;br&gt;不知道这样讲可以不？<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-04-19" target="_blank" href="/question/23453503/answer/24676685">编辑于 2014-04-19</a></span></textarea><div class="zh-summary summary clearfix">试着回答一下前两个1）线性回归（Linear Regression）：假设你在纸上画了一堆点，然后打算画一条线，这些点到这条线的距离尽量得短。怎么找这条线呢？方法就是Linear Regression。有了这条线，希望用它来预测之后出现的点都会在它附近。2）贝叶思（Bayes Th…<a href="/question/23453503/answer/24676685" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-1562707"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>4 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='17'><meta itemprop="answer-id" content="16231680" /><meta itemprop="answerCount" content="3" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/31464378">贝叶斯（bayesian）防止过拟合的确切机理？边缘化（marginalizing）的真实作用是什么？</a></h2><div class="entry-body "data-aid="16231680"data-atoken="52068253"data-collapsed="False"data-created="1434805028"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="10">10</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">10</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$he-lei-code" href="/people/he-lei-code">dontbeatmycat</a>，<span title="憋打猫猫！" class="bio">憋打猫猫！</span></div><div class="zm-item-vote-info " data-votecount="10"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$albert-yang-68" href="http://www.zhihu.com/people/albert-yang-68" class="zg-link" title="Aquila">Aquila</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="4785013" data-action="/answer/content" data-author-name="dontbeatmycat" data-entry-url="/question/31464378/answer/52068253"><textarea class="content hidden">1. 引入 prior 的回归/分类，或者说 MAP estimator（最大后验估计）不能算是贝叶斯方法。完整的贝叶斯方法并不止步于算出 posterior 的 mode 或者 mean，而是&lt;b&gt;利用整个 posterior 分布对预测过程进行平滑&lt;/b&gt;，具体来说就是：&lt;br&gt;&lt;br&gt;假设 posterior 为&lt;img src=&quot;//zhihu.com/equation?tex=P%28%5Ctheta%7CD%2C+M%29&quot; alt=&quot;P(\theta|D, M)&quot; eeimg=&quot;1&quot;&gt; ，其中 D 是数据集，M 是模型，&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt; 是模型参数；&lt;br&gt;假设给定参数后，对于新数据 x 的预测函数为 &lt;img src=&quot;//zhihu.com/equation?tex=P%28x%7C%5Ctheta%2C+M%29&quot; alt=&quot;P(x|\theta, M)&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;在课本中 M 通常被忽略，因为通常我们只研究一个模型，但是如果要比较多个不同模型，那么 M 不能忽略。&lt;br&gt;&lt;br&gt;所谓贝叶斯回归，就是计算一个预测分布（predictive distribution）：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Cint+P%28x%7C%5Ctheta%2C+M%29+P%28%5Ctheta%7CD%2CM%29+d%5Ctheta%3DP%28x%7CD%2CM%29&quot; alt=&quot;\int P(x|\theta, M) P(\theta|D,M) d\theta=P(x|D,M)&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;这个预测分布可以这么理解，将不同&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;对应的预测结果组合起来，形成最终的预测结果，而组合的权重就根据&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;的 posterior 的大小，由于&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;是一个连续的随机变量，所以这个“组合”就是一个积分。 &lt;br&gt;&lt;br&gt;再看MAP，它能够降低过拟合，但是不能避免过拟合，因为 MAP 假定参数只会取一个固定的值，而不是一个分布，这是一种过度自信的表现，更具体来说，MAP 将上面的 &lt;img src=&quot;//zhihu.com/equation?tex=P%28%5Ctheta%7CD%2CM%29&quot; alt=&quot;P(\theta|D,M)&quot; eeimg=&quot;1&quot;&gt;近似为一个 delta  函数&lt;img src=&quot;//zhihu.com/equation?tex=%5Cdelta%28%5Ctheta+-+%5Chat%7B%5Ctheta%7D%29&quot; alt=&quot;\delta(\theta - \hat{\theta})&quot; eeimg=&quot;1&quot;&gt;，从而忽略了&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt; 的不确定性。（式中&lt;img src=&quot;//zhihu.com/equation?tex=%5Chat%7B%5Ctheta%7D&quot; alt=&quot;\hat{\theta}&quot; eeimg=&quot;1&quot;&gt; 是 posterior 的 mode 点）&lt;br&gt;&lt;br&gt;2. 再说边缘似然 &lt;img src=&quot;//zhihu.com/equation?tex=P%28D%7CM%29&quot; alt=&quot;P(D|M)&quot; eeimg=&quot;1&quot;&gt;，它实际上可以用上面的预测分布连乘来表示：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=P%28D%7CM%29+%3D%0AP%28x_1%2Cx_2%2C...%2Cx_n%7CM%29%3D%0AP%28x_1%7CM%29P%28x_2%7Cx_1%2CM%29P%28x_3%7Cx_1%2Cx_2%2CM%29..P%28x_n%7Cx_%7B1..n-1%7D%2CM%29&quot; alt=&quot;P(D|M) =P(x_1,x_2,...,x_n|M)=P(x_1|M)P(x_2|x_1,M)P(x_3|x_1,x_2,M)..P(x_n|x_{1..n-1},M)&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;这个过程可以理解为，我们先计算模型生成 x1 的概率，然后乘以 x1 为训练集时 x2 的预测分布，依次类推。显然，如果一个模型过于复杂，那么预测分布值会较小（因为预测性能不好），那么在连乘后，得到的边缘似然也很小。（这实际上是 MLAPP 上的解释，见公式 5.14），所以边缘似然可以用来做模型选择。&lt;br&gt;&lt;br&gt;最后，为什么似然函数最大值&lt;img src=&quot;//zhihu.com/equation?tex=P%28D%7C%5Chat%7B%5Ctheta%7D%2C+M%29&quot; alt=&quot;P(D|\hat{\theta}, M)&quot; eeimg=&quot;1&quot;&gt;不能用来做模型选择呢？因为很可能是由于模型的能力过强，导致它能完美拟合的数据集过多（复杂度过高），所以很容易就 fit 训练集了，而边缘似然呢：&lt;br&gt;&lt;img src=&quot;//zhihu.com/equation?tex=%5Cint+P%28D%7C%5Ctheta%2CM%29P%28%5Ctheta%29+d%5Ctheta&quot; alt=&quot;\int P(D|\theta,M)P(\theta) d\theta&quot; eeimg=&quot;1&quot;&gt;&lt;br&gt;它考虑到了参数 &lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt; 的分布，并且将每个不同&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;生成数据集的概率组合起来，和之前一样，这个组合是个积分。你看，如果&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;的可能性很多（模型复杂），但只有一种的似然函数值大，那么最终积分的结果是很小的。只有【&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;的可能性相对较少（简单的模型），其中某些&lt;img src=&quot;//zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;&gt;使似然函数较大】的情况下，这个积分才会较大，从而，边缘似然可以来做模型选择。&lt;br&gt;&lt;br&gt;3. 综上所述，贝叶斯方法本质上就是一个平均，平滑（averaging），这里我们只考虑了单层的贝叶斯模型，实际上，贝叶斯方法在多层的超参数存在时照样十分自然优美，不过是多几重积分而已。通过平均，融合了不同的可能性，使得预测结果更加稳定。其实线性回归并不是贝叶斯方法最常用的地方，而是自然语言处理中的语言模型里的 add-x smoothing（加x平滑），所谓加x平滑实际上是 multinomial 分布加上狄利克雷先验后的预测分布。上述所有内容都总结自 MLAPP 第五章，还可以参考这篇教程：&lt;a href=&quot;http://www.arbylon.net/publications/text-est.pdf&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;arbylon.net/publication&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/text-est.pdf&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;4. 另外，从以上内容可以看出，贝叶斯方法的核心部件，就是 posterior，而对于复杂模型来说，这个 posterior 是很难算的，于是，机器学习中的拉普拉斯近似，变分法，MCMC 采样等就派上了用场。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2015-06-20" target="_blank" href="/question/31464378/answer/52068253">编辑于 2015-06-20</a></span></textarea><div class="zh-summary summary clearfix">1. 引入 prior 的回归/分类，或者说 MAP estimator（最大后验估计）不能算是贝叶斯方法。完整的贝叶斯方法并不止步于算出 posterior 的 mode 或者 mean，而是<b>利用整个 posterior 分布对预测过程进行平滑</b>，具体来说就是：假设 posterior 为P(\theta|D, M) ，…<a href="/question/31464378/answer/52068253" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-4785013"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>1 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='18'><meta itemprop="answer-id" content="11086367" /><meta itemprop="answerCount" content="5" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/27872148">回归系数检验的问题？</a></h2><div class="entry-body "data-aid="11086367"data-atoken="39235669"data-collapsed="False"data-created="1423384647"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="7">7</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">7</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><span class="name">知乎用户</span>，<span title="生命科学，经济学，工业工程，统计学" class="bio">生命科学，经济学，工业工程，统计学</span></div><div class="zm-item-vote-info " data-votecount="7"><span class="voters"><span class="user-block"><a data-tip="p$t$li-zongh" href="http://www.zhihu.com/people/li-zongh" class="zg-link" title="li zongh">li zongh</a>、</span><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$__INT" href="http://www.zhihu.com/people/__INT" class="zg-link" title="INT">INT</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="3331680" data-action="/answer/content" data-author-name="秦松雄" data-entry-url="/question/27872148/answer/39235669"><textarea class="content hidden">频率学派（我们以下所说的都是频率学派的内容，区别于贝叶斯学派，详见”&lt;a href=&quot;http://www.zhihu.com/question/20587681/answer/23060072&quot; class=&quot;internal&quot;&gt;贝叶斯学派与频率学派有何不同？ - 知乎用户的回答&lt;/a&gt;“）的观点是，参数存在客观的绝对真理，但通过取样估计不能看到背后的绝对真理，只能模糊地看见参数大致的位置，原因在于存在额外的噪声。在这个例子中，零假设（回归系数=0）就是对回归系数这个永恒真理的猜想。&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;H0：绝对真理的回归系数=0&lt;br&gt;如果H0成立，也就是如果绝对真理回归系数=0，那么在一次抽样中，由于抽样误差引入的噪声，致于估计出的回归系数不可能精准地等于0。多次&lt;b&gt;重复&lt;/b&gt;抽样的结果亦如此，每次抽样都能得到一个对于回归系数的估计，但这些估计值都不可能精准地等于0，而是在0附近的若干值。通常，这些估计值靠近0的可能性大，远离0的可能性小。特殊情况就是服从正态分布。&lt;br&gt;&lt;br&gt;假设检验的逻辑是一句不证自明的话：“小概率事件在一次抽样中难以发生”。&lt;br&gt;&lt;br&gt;如果H0成立，那么通过抽样而得到的参数估计值应当服从某个统计分布。而我们通常不会重复若干次抽样，而是只抽&lt;b&gt;一次&lt;/b&gt;，得到&lt;b&gt;一个&lt;/b&gt;估计值。这个估计值应当在真值附近波动。&lt;br&gt;&lt;br&gt;在本例中，这段话翻译为，如果绝对真理的回归系数=0，那么在重复抽样中，通过样本估计的回归系数应当服从某个统计分布，具体而言，是以0为期望的某个分布。如果在一次抽样中，得到的一个估计值a偏离0太远，以至于在H0成立的假设下，如果要抽到比a还极端（离0更远）的值，其可能性小于某个阈值（习惯用5%，这种预先设定α说法是基于E. Pearson和J. Nayman的假设检验理论，区别于Fisher的尾区概率p值的理论，详见”&lt;a href=&quot;http://www.zhihu.com/question/23149768/answer/25557020&quot; class=&quot;internal&quot;&gt;统计学假设检验中 p 值的含义具体是什么？ - 知乎用户的回答&lt;/a&gt;“），那么得到估计值a就是小概率事件。统计学家们相信自己没有那么点儿背，一次抽样就抽到一个小概率事件，所以倾向于认为是H0错误导致的，于是拒绝H0，认为绝对真理的回归系数应当是某个非零值。&lt;br&gt;&lt;br&gt;但如果碰巧H0还就真是等于零，而我们因为得到了极端估计值a所以否决掉了H0，这样的判断就犯下了错误。&lt;br&gt;&lt;br&gt;&lt;b&gt;&lt;u&gt;频率学派假设检验的解读，一定是建立在重复抽样之上的。&lt;/u&gt;&lt;/b&gt;&lt;br&gt;&lt;br&gt;也就是说，如果零假设正确，那么抽样100次，得到100个估计值，平均可能得到5个极端估计值，如果我们因此而拒绝零假设，就会有5次机会做出错误的论断。&lt;br&gt;&lt;br&gt;一旦谙熟这一套逻辑，我们来看这句话的意思。&lt;br&gt;&lt;br&gt;“若拒绝H0(回归系数为0)，表示回归系数等于0的可能性小于0.05。”&lt;br&gt;&lt;br&gt;首先，“回归系数等于0的可能性”本身不是频率学派的说法。在频率学派中，回归系数的取值是绝对真理的某个取值，不能讨论其概率。讨论其概率是贝叶斯学派的做法。所以在本句话中的“可能性”并不是讨论其概率的意思。&lt;br&gt;&lt;br&gt;其次，“可能性”在本句中的意思应该是我们做出统计推断的“信心”，对于“信心”的解读就需要用到重复取样的思路。如果零假设正确，按照这样的假设检验的方法和判断流程，抽样100次，得到100个估计值，平均可能得到5个极端估计值，如果我们因此而拒绝零假设，就会有5次机会做出错误的论断。现在我抽取了一次样本，取到了极端值而拒绝之，认为回归系数不等于0，而如果绝对真理的回归系数=0，则我的&lt;b&gt;这一套方法&lt;/b&gt;得出错误结论的机会大概是每重复抽样100次犯5次（回归系数真实=0，而我判断其不等于0的可能性=0.05）。如果当初设定的阈值是40%，那么我的&lt;b&gt;这一套方法&lt;/b&gt;得出错误结论的机会大概是每重复100次犯40次（回归系数真实=0，而我判断其不等于0的可能性=0.4）。&lt;br&gt;&lt;br&gt;可见，这个阈值（0.05或0.4）描述的是&lt;b&gt;这一套方法&lt;/b&gt;在重复取样中犯”否定正确零假设“这一错误的概率，反映的是对&lt;b&gt;这套方法&lt;/b&gt;的”信心“。<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/27872148/answer/39235669">发布于 2015-02-08</a></span></textarea><div class="zh-summary summary clearfix">频率学派（我们以下所说的都是频率学派的内容，区别于贝叶斯学派，详见”<a href="http://www.zhihu.com/question/20587681/answer/23060072" class="internal">贝叶斯学派与频率学派有何不同？ - 知乎用户的回答</a>“）的观点是，参数存在客观的绝对真理，但通过取样估计不能看到背后的绝对真理，只能模糊地看见参数大致的位置，原因在于存在额外…<a href="/question/27872148/answer/39235669" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-3331680"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>添加评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='19'><meta itemprop="answer-id" content="9802009" /><meta itemprop="answerCount" content="1" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/27269819">在线性回归(linear regression)中, 过拟合(over-fitting)和多重共线性(multicollinearity)是一会儿事么？</a></h2><div class="entry-body "data-aid="9802009"data-atoken="36032379"data-collapsed="False"data-created="1419782376"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="8">8</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">8</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><span class="name">知乎用户</span></div><div class="zm-item-vote-info " data-votecount="8"><span class="voters"><span class="user-block"><a data-tip="p$t$wu-renee" href="http://www.zhihu.com/people/wu-renee" class="zg-link" title="Wu Renee">Wu Renee</a>、</span><span class="user-block"><a data-tip="p$t$yang-ai-sen" href="http://www.zhihu.com/people/yang-ai-sen" class="zg-link" title="杨艾森">杨艾森</a>、</span><span class="user-block"><a data-tip="p$t$ren-ran-32-96" href="http://www.zhihu.com/people/ren-ran-32-96" class="zg-link" title="任然">任然</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="3090849" data-action="/answer/content" data-author-name="路路" data-entry-url="/question/27269819/answer/36032379"><textarea class="content hidden">不是一回事情。&lt;br&gt;&lt;br&gt;&lt;b&gt;过拟合(over-fitting)&lt;/b&gt;指的是你建模的时候用了过多的参数，&lt;b&gt;一般地，我们建模的时候要让参数个数尽可能的少。&lt;/b&gt;然后，只要你的模型参数有很多，做出来的R平方也可以很好看。所以，为了避免这种情况，就有了&lt;b&gt;Akaike information criterion和Bayesian information criterion&lt;/b&gt;等判定准则，大致原理是你用的参数越少，这个值则越大，模型越棒！&lt;br&gt;&lt;b&gt;多重共线性(multicollinearity)&lt;/b&gt;指的是你建模的时候，&lt;b&gt;解释变量之间有高度相关性&lt;/b&gt;。这种情况的表现就是：&lt;b&gt;你在做test statistics时候，单个解释变量不显著，整体确实显著的。这样一一来你的模型的参数估计是没有意义的！&lt;/b&gt;所以，我们经常要判断这种关系存不存在，有的方法主流的就是首先在variable selection用s&lt;b&gt;tepwise regression&lt;/b&gt;把这种关系先杜绝掉，或者是&lt;b&gt;VIF来判断，方差膨胀因子&lt;/b&gt;表达式为：VIFi=1/（1-R2i)。其中Ri为自变量xi对其余自变量作回归分析的复相关系数。当VIFi很大时，表明自变量间存在多重共线性。一般大于10就说有多重共线性存在。&lt;br&gt;&lt;br&gt;我觉得区别就是&lt;b&gt;一个是你人为地加了太多变量，另一个是&lt;/b&gt;&lt;b&gt;数据的限制使得模型设计不当 。&lt;/b&gt;&lt;br&gt;&lt;br&gt;希望能帮到你。<span class="answer-date-link-wrap"><a class="answer-date-link last_updated meta-item" data-tip="s$t$发布于 2014-12-28" target="_blank" href="/question/27269819/answer/36032379">编辑于 2014-12-29</a></span></textarea><div class="zh-summary summary clearfix">不是一回事情。<b>过拟合(over-fitting)</b>指的是你建模的时候用了过多的参数，<b>一般地，我们建模的时候要让参数个数尽可能的少。</b>然后，只要你的模型参数有很多，做出来的R平方也可以很好看。所以，为了避免这种情况，就有了<b>Akaike information criterion和Bayesia…</b><a href="/question/27269819/answer/36032379" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-3090849"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>7 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div><div class="feed-item feed-item-hook folding" itemprop="question" itemscope itemtype="http://schema.org/Question" data-score='20'><meta itemprop="answer-id" content="11083981" /><meta itemprop="answerCount" content="3" /><meta itemprop="isTopQuestion" content="false" /><div class="feed-main"><div class="content"><h2><a class="question_link" target="_blank" href="/question/28050978">为什么变量间的相关关系会使变量系数不能通过t检验？</a></h2><div class="entry-body "data-aid="11083981"data-atoken="39229721"data-collapsed="False"data-created="1423378498"data-deleted="0"data-isowner="0"data-helpful="1"data-score="0"data-copyable="1"><div class="zm-item-vote"><a class="zm-item-vote-count js-expand js-vote-count" href="javascript:;" data-votecount="9">9</a></div><div class="zm-votebar"><button class="up "><i class="icon vote-arrow"></i><span class="count">9</span><span class="label sr-only">赞同</span></button><button class="down "><i class="icon vote-arrow"></i><span class="label sr-only">反对</span></button></div><div class="zm-item-answer-detail"><div class="zm-item-answer-author-info"><a class="author-link" data-tip="p$t$sijichun" href="/people/sijichun">慧航</a>，<span title="公众号:ecopaper，Keep calm and DO your Research" class="bio">公众号:ecopaper，Keep calm and DO your…</span></div><div class="zm-item-vote-info " data-votecount="9"><span class="voters"><span class="user-block">知乎用户、</span><span class="user-block"><a data-tip="p$t$sheepsheep" href="http://www.zhihu.com/people/sheepsheep" class="zg-link" title="Sheep DLY">Sheep DLY</a>、</span><span class="user-block"><a data-tip="p$t$zhao-xiao-hang-9" href="http://www.zhihu.com/people/zhao-xiao-hang-9" class="zg-link" title="赵晓航">赵晓航</a></span></span><a href="javascript:;" class="more"> 等人赞同</a></div><div class="zm-item-rich-text js-collapse-body" data-resourceid="3403054" data-action="/answer/content" data-author-name="慧航" data-entry-url="/question/28050978/answer/39229721"><textarea class="content hidden">谢邀。你说的这叫多重共线性。&lt;br&gt;这个问题回答很多次了，本不想回答。不过你想问为什么，可以从这么几个方面来思考。&lt;br&gt;从线性代数来考虑，想一个极端情况，如果是完全共线会发生什么？对，矩阵不可逆了。如果不是完全共线，仅仅是强相关，那么矩阵的逆矩阵就会非常不稳定（可以用条件数判断），稍微一点扰动就会造成结果很大的改变。&lt;br&gt;当然更直接的是考虑系数的协方差矩阵。相关性越强，则其逆矩阵的对角线越大，也就是系数方差越大（&lt;img src=&quot;//zhihu.com/equation?tex=%5Csigma%5E2%28X%27X%29%5E%7B-1%7D&quot; alt=&quot;\sigma^2(X'X)^{-1}&quot; eeimg=&quot;1&quot;&gt;），下面举个例子，看看相关性为0.9和0.2其逆矩阵的对角线元的大小。&lt;br&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;julia&amp;gt; a=[1 0.9;.9 1]2x2 Array{Float64,2}: 1.0  0.9 0.9  1.0julia&amp;gt; inv(a)2x2 Array{Float64,2}:  5.26316  -4.73684 -4.73684   5.26316julia&amp;gt; a=[1 0.2;.2 1]2x2 Array{Float64,2}: 1.0  0.2 0.2  1.0julia&amp;gt; inv(a)2x2 Array{Float64,2}:  1.04167   -0.208333 -0.208333   1.04167 &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;还有，最直白的理解，你的工作经验每年都在增加，时间也在一年又一年，你怎么知道你的收入增加是因为工作经验还是大的趋势？这个时候你能用的信息很少，因为两个一起变，相关性很高。但是你中途间隔年了，工作经验不增加了，时间还在走，这个时候相关性就低了，你才可以看到底咋回事。<span class="answer-date-link-wrap"><a class="answer-date-link meta-item" target="_blank" href="/question/28050978/answer/39229721">发布于 2015-02-08</a></span></textarea><div class="zh-summary summary clearfix">谢邀。你说的这叫多重共线性。这个问题回答很多次了，本不想回答。不过你想问为什么，可以从这么几个方面来思考。从线性代数来考虑，想一个极端情况，如果是完全共线会发生什么？对，矩阵不可逆了。如果不是完全共线，仅仅是强相关，那么矩阵的逆矩阵就会非…<a href="/question/28050978/answer/39229721" class="toggle-expand">显示全部</a></div></div></div></div><div class="zm-item-meta feed-meta"><div class="zm-item-meta zm-item-comment-el answer-actions clearfix"><div class="zm-meta-panel"><a data-follow="q:link" class="follow-link zg-follow meta-item" href="javascript:;" id="sfb-3403054"><i class="z-icon-follow"></i>关注问题</a><a href="#" name="addcomment" class=" meta-item toggle-comment"><i class="z-icon-comment"></i>4 条评论</a><a href="#" class="meta-item zu-autohide" name="thanks" data-thanked="false"><i class="z-icon-thank"></i>感谢</a><a href="#" class="meta-item zu-autohide" name="share"><i class="z-icon-share"></i>分享</a><a href="#" class="meta-item zu-autohide" name="favo"><i class="z-icon-collect"></i>收藏</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="nohelp" class="meta-item zu-autohide">没有帮助</a><span class="zg-bull zu-autohide">&bull;</span><a href="#" name="report" class="meta-item zu-autohide">举报</a><span class="zg-bull">&bull;</span><a href="/terms#sec-licence-1" target="_blank" class="meta-item copyright"> 作者保留权利 </a><button class="meta-item item-collapse js-collapse"><i class="z-icon-fold"></i>收起</button></div></div></div></div></div></div></div><div class="zm-invite-pager"><span class="zg-gray-normal">上一页</span><span class="zg-gray-normal">1</span><span><a href="?page=2">2</a></span><span><a href="?page=2">下一页</a></span></div></div></div></div></div><div class="zu-main-sidebar"><div class="zm-side-section"><div class="zm-side-section-inner"><div class="well login-reg-box"><span>知乎是一个真实的问答社区，在这里分享知识、经验和见解，发现更大的世界。<br><a id="js-reg-with-mail-in-top" href="#">使用手机或邮箱注册</a><!-- <span>·</span><a id="js-reg-with-qq-in-top" href="#">使用 QQ 登录</a> --></span><div class="clearfix"><a id="js-reg-with-wechat-in-top" href="#" class="zg-btn-green"><span class="z-ico-wechat-right-panel"></span>使用微信登录</a><a id="js-reg-with-sina-in-top" href="#" class="zg-btn-red"><span class="icon-big-white-sina"></span>使用微博登录</a><a id="js-reg-with-qq-in-top" href="#" class="zg-btn-blue"><span class="icon-big-white-qq"></span>使用 QQ 登录</a></div></div></div></div><div class="zm-side-section"><div class="zm-side-section-inner"><div class="topic-header-side zm-entry-head-wrap"><div class="clearfix"><div id="zh-topic-side-head"><a href="javascript:;" id="tf-33508" name="focus" class="zg-btn-green topic-follow-button zu-entry-focus-button">关注</a><div class="zm-topic-side-followers-info"><strong>373</strong> 人关注了该话题</div></div></div></div></div></div><div class="shameimaru-placeholder" data-class="TopicUpShameimaruV2" data-params='{&quot;token&quot;:&quot;19650500&quot;}'></div><div class="zm-side-section" id="zh-topic-side-parents-list"><div class="zm-side-section-inner parent-topic"><h3 class="zm-topic-side-organize-title">父话题</h3><div class="clearfix"><a class="zm-item-tag"href="/topic/19577456"data-tip="t$b$19577456" data-token="19577456" data-topicid="9078">回归分析</a></div></div></div><div class="zm-side-section"><div class="zm-side-section-inner"><h3>话题动态</h3><ul class="zh-question-related-questions" itemprop="relatedQuestion" itemscope itemtype="http://schema.org/ItemList"><li itemprop="itemListElement" itemscope itemtype="http://schema.org/Question"><a class="question_link" href="/question/36845076">线性代数有什么用？学习线性代数的意义在哪？</a> <span class="num">60 个回答</span><meta itemprop="followerCount" content="731" /></li><li itemprop="itemListElement" itemscope itemtype="http://schema.org/Question"><a class="question_link" href="/question/38017657">线性回归里参数的假设检验都有哪些，分别有什么优劣，如何理解呢？</a> <span class="num">2 个回答</span><meta itemprop="followerCount" content="29" /></li><li itemprop="itemListElement" itemscope itemtype="http://schema.org/Question"><a class="question_link" href="/question/27007650">平均来讲，我们对一张面孔的相貌评价会随着看到这张脸的次数增加而发生什么样的变化？</a> <span class="num">551 个回答</span><meta itemprop="followerCount" content="6847" /></li></ul></div></div><div class="shameimaru-placeholder" data-class="TopicDownShameimaruV2" data-params='{&quot;token&quot;:&quot;19650500&quot;}'></div></div></div><div id="zh-footer" class="zh-footer"><div class="content zg-wrap clearfix"><ul><li><a href="https://liukanshan.zhihu.com" target="_blank">刘看山</a></li><li><a href="/app" target="_blank">移动应用</a></li><li><a href="/careers">加入知乎</a></li><li><a href="/terms" target="_blank">知乎协议</a></li><li><a href="mailto:bd@zhihu.com">商务合作</a></li></ul><span class="copy">&copy; 2015 知乎</span></div></div><script type="text/json" class="json-inline" data-name="guiders2">{}</script><script type="text/json" class="json-inline" data-name="current_user">["","","","-1","",0,0]</script><script type="text/json" class="json-inline" data-name="env">["zhihu.com","comet.zhihu.com",false,null]</script><script type="text/json" class="json-inline" data-name="permissions">[]</script><script type="text/json" class="json-inline" data-name="ga_vars">{"user_created":0,"now":1449128470000,"abtest_mask":"------------------------------","user_attr":[0,0,0,"-","-"],"user_hash":0}</script><script type="text/json" class="json-inline" data-name="current_topic">[["\u7ebf\u6027\u56de\u5f52","19650500","https:\/\/pic4.zhimg.com\/1786ec53f_s.jpg",33508],[["\u56de\u5f52\u5206\u6790","19577456","https:\/\/pic1.zhimg.com\/e82bab09c_s.jpg"]],0,0,"",0]</script><script src="http://static.zhihu.com/static/revved/-/js/vendor.1a51eb6e.js"></script><script src="http://static.zhihu.com/static/revved/-/js/closure/common.d3bfcd50.js"></script><script src="http://static.zhihu.com/static/revved/-/js/closure/richtexteditor.4bc37c3f.js" async></script><script src="http://static.zhihu.com/static/revved/-/js/closure/page-main.7d067a7b.js"></script><meta name="entry" content="ZH.entryT" data-module-id="page-main"><script type="text/zscript" znonce="baff6fbaeaad46cd8ff0c01b0ed6924c"></script><input type="hidden" name="_xsrf" value="2d5ac254df3ddfc19dd98a4bcca0f770"/></body></html>